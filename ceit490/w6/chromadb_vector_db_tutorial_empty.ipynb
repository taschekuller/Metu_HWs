{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "66f7e28284095f80",
      "metadata": {
        "id": "66f7e28284095f80"
      },
      "source": [
        "# Embeddings and Vector Databases With ChromaDB\n",
        "\n",
        "Modern LLMs, while imperfect, can accurately solve a wide range of problems and provide correct answers to many questions. But, due to the limits of their training and the number of text tokens they can process, LLMs aren’t a silver bullet for all tasks.\n",
        "\n",
        "You wouldn’t expect an LLM to provide relevant responses about topics that don’t appear in their training data. For example, if you asked ChatGPT to summarize information in confidential company documents, then you’d be out of luck. You could show some of these documents to ChatGPT, but there’s a limited number of documents that you can upload before you exceed ChatGPT’s maximum number of tokens. How would you select documents to show ChatGPT?\n",
        "\n",
        "To address these shortcomings and scale your LLM applications, one great option is to use a vector database like ChromaDB. A vector database allows you to store encoded unstructured objects, like text, as lists of numbers that you can compare to one another. You can, for example, find a collection of documents relevant to a question that you want an LLM to answer.\n",
        "\n",
        "## Represent Data as Vectors\n",
        "\n",
        "Before diving into embeddings and vector databases, you should understand what vectors are and what they represent.\n",
        "\n",
        "You can describe vectors with variable levels of complexity, but one great starting place is to think of a vector as an array of numbers. For example, you could represent vectors using NumPy arrays as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e93612ecde021093",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e93612ecde021093",
        "outputId": "62f804c2-04a4-468d-d4a9-74680ed2662f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "initial_id",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-16T09:16:32.806535Z",
          "start_time": "2024-11-16T09:16:32.747025Z"
        },
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "initial_id",
        "outputId": "fb04b6a5-c30d-478c-95b0-90eef28e4956"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0]\n",
            "[0 1]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "vector1 = np.array([1, 0])\n",
        "vector2 = np.array([0, 1])\n",
        "\n",
        "print(vector1)\n",
        "print(vector2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "495d2177103e32c0",
      "metadata": {
        "id": "495d2177103e32c0"
      },
      "source": [
        "In this code block, you import numpy and create two arrays, vector1 and vector2, representing vectors. This is one of the most common and useful ways to work with vectors in Python, and NumPy offers a variety of functionality to manipulate vectors.\n",
        "\n",
        "You’ve created two NumPy arrays that represent vectors. Now what? It turns out you can do a lot of cool things with vectors, but before continuing on, you’ll need to understand some key definitions and properties:\n",
        "\n",
        "* **Dimension:** The dimension of a vector is the number of elements that it contains. In the example above, `vector1` and `vector2` are both two-dimensional since they each have two elements. You can only visualize vectors with three dimensions or less, but generally, vectors can have any number of dimensions. In fact, as you’ll see later, vectors that encode words and text tend to have hundreds or thousands of dimensions.\n",
        "\n",
        "* **Magnitude:** The magnitude of a vector is a non-negative number that represents the vector’s size or length. You can also refer to the magnitude of a vector as the norm, and you can denote it with `||v||` or `|v|`. There are many different definitions of magnitude or norm, but the most common is the *Euclidean norm* or *2-norm*. You’ll learn how to compute this later.\n",
        "\n",
        "* **Unit vector:** A unit vector is a vector with a magnitude of one. In the example above, `vector1` and `vector2` are unit vectors.\n",
        "\n",
        "* **Direction:** The direction of a vector specifies the line along which the vector points. You can represent direction using angles, unit vectors, or coordinates in different coordinate systems.\n",
        "\n",
        "* **Dot product (scalar product):** The dot product of two vectors, u and v, is a number given by `u ⋅ v = ||u|| ||v|| cos(θ)`, where `θ` is the angle between the two vectors. Another way to compute the dot product is to do an *element-wise multiplication of u and v and sum the results*. The dot product is one of the most important and widely used vector operations because it measures the similarity between two vectors. You’ll see more of this later on.\n",
        "\n",
        "* **Orthogonal vectors:** Vectors are *orthogonal* if their dot product is zero, meaning that they’re at a 90 degree angle to each other. You can think of orthogonal vectors as being completely *unrelated* to each other.\n",
        "\n",
        "* **Dense vector:** A vector is considered dense if most of its elements are non-zero. Later on, you’ll see that words and text are most usefully represented with dense vectors because each dimension encodes meaningful information.\n",
        "\n",
        "While there are many more definitions and properties to learn, these six are most important for this tutorial. Note that for the rest of this tutorial, you’ll use `v1`, `v2`, and `v3` to name your vectors.\n",
        "\n",
        "You first import numpy and create the arrays v1, v2, and v3. Calling v1.shape shows you the dimension of v1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a1571c7868b8875",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-16T17:57:55.693932Z",
          "start_time": "2024-11-16T17:57:55.690471Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a1571c7868b8875",
        "outputId": "3aa027a9-ffac-4d5e-f73f-509dfde10834"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2,)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "v1 = np.array([1, 0])\n",
        "v2 = np.array([0, 1])\n",
        "v3 = np.array([np.sqrt(2), np.sqrt(2)])\n",
        "\n",
        "# Dimension\n",
        "v1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bd9fbe5bca37d16",
      "metadata": {
        "id": "4bd9fbe5bca37d16"
      },
      "source": [
        "You then see two different ways to compute the magnitude of a NumPy array. The first, `np.sqrt(np.sum(v1**2))`, uses the Euclidean norm that you learned about above. The second computation uses `np.linalg.norm()`, a NumPy function that computes the Euclidean norm of an array by default but can also compute other matrix and vector norms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a28c65ec736583c0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-16T06:16:31.875389Z",
          "start_time": "2024-11-16T06:16:31.871519Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a28c65ec736583c0",
        "outputId": "08abc4bd-c02c-4d88-a249-d08cdd0e03ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***1.0\n",
            "1.0\n",
            "1.0\n",
            "2.0\n"
          ]
        }
      ],
      "source": [
        "# Magnitude\n",
        "v1_magnitude = np.linalg.norm(v1)\n",
        "v2_magnitude = np.linalg.norm(v2)\n",
        "v3_magnitude = np.linalg.norm(v3)\n",
        "\n",
        "test = np.sqrt(np.sum(v1**v2))\n",
        "print(f\"***{test}\")\n",
        "\n",
        "print(v1_magnitude)\n",
        "print(v2_magnitude)\n",
        "print(v3_magnitude)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "755c70cd1a23a9ad",
      "metadata": {
        "id": "755c70cd1a23a9ad"
      },
      "source": [
        "By default, `np.linalg.norm(v1)` calculates the L2 norm (also known as the *Euclidean* norm) of the vector `v1`. This is the most common type of norm and corresponds to the usual notion of distance in Euclidean space.\n",
        "\n",
        "Here's how the *L2 norm* is calculated:\n",
        "\n",
        "1. Square each element of the vector v1.\n",
        "2. Sum all the squared elements.\n",
        "3. Take the square root of the sum.\n",
        "\n",
        "4. Example:\n",
        "\n",
        "If `v1 = np.array([3, 4])`, then:\n",
        "\n",
        "1. Square each element: [3 ** 2, 4 ** 2] = [9, 16]\n",
        "2. Sum the squared elements: `9 + 16 = 25`\n",
        "3. Take the square root: `sqrt(25) = 5`\n",
        "\n",
        "Therefore, `np.linalg.norm(v1) = 5`\n",
        "\n",
        "Lastly, below you see two ways to calculate the dot product between two vectors. Using `np.sum(v1 * v2)` first computes the element-wise multiplication between `v1` and `v2` in a vectorized fashion, and you sum the results to produce a single number. A better way to compute the dot product is to use the at-operator `(@)`, as you see with `v1 @ v3`. This is because `@` can perform both vector and matrix multiplications, and the syntax is cleaner."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3f545a1bc14e4e0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-15T12:58:28.347056Z",
          "start_time": "2024-11-15T12:58:28.338868Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3f545a1bc14e4e0",
        "outputId": "f0fa74e3-be64-420b-b0cf-f8b5999f97f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.0"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Dot product\n",
        "a1 = np.array([3, 0])\n",
        "a2 = np.array([0, 4])\n",
        "b1 = np.array([3, 4])\n",
        "np.sum(a1*a2)\n",
        "# print(a1.dot(a2))\n",
        "\n",
        "np.linalg.norm(b1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e84861d4dbb50f2",
      "metadata": {
        "id": "4e84861d4dbb50f2"
      },
      "source": [
        "While all of these vector definitions and properties may seem straightforward to compute, you might still be wondering what they actually mean and why they’re important to understand. One way to better understand vectors is to visualize them in two dimensions. In this context, you can represent vectors as arrows, like in the following plot:\n",
        "\n",
        "\n",
        "<img src=\"vectors-graph.avif\">\n",
        "\\\n",
        "\n",
        "The above plot shows the visual representation of the vectors `v1`, `v2`, and `v3` that you worked with in the last example. The tail of each vector arrow always starts at the origin, and the tip is located at the coordinates specified by the vector. As an example, the tip of `v1` lies at (1, 0), and the tip of `v3` lies at roughly (1.414, 1.414). The length of each vector arrow corresponds to the magnitude that you calculated earlier.\n",
        "\n",
        "From this visual, you can make the following key inferences:\n",
        "\n",
        "1. `v1` and `v2` are unit vectors because their magnitude, given by the arrow length, is one. `v3` isn’t a unit vector, and its magnitude is two, twice the size of `v1` and `v2`.\n",
        "\n",
        "2. `v1` and `v2` are orthogonal because their tails meet at a 90 degree angle. You see this visually but can also verify it computationally by computing the dot product between `v1` and `v2`. By using the dot product definition, `v1 ⋅ v2 = ||v1|| ||v2|| cos(θ)`, you can see that when `θ = 90`, `cos(θ) = 0` and `v1 ⋅ v2 = 0`. Intuitively, you can think of `v1` and `v2` as being totally unrelated or having nothing to do with each other. This will become important later.\n",
        "\n",
        "3. `v3` makes a 45 degree angle with both `v1` and `v2`. This means that `v3` will have a non-zero dot product with `v1` and `v2`. This also means that `v3` is equally related to both `v1` and `v2`. In general, the smaller the angle between two vectors, the more they point toward a common direction.\n",
        "\n",
        "You’ve now seen how vectors are characterized both computationally and visually. With this understanding, you’re ready to take a slightly deeper dive into the idea of vector similarity. If you only take away one thing from this introduction, it should be what follows."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7c55b32548497b",
      "metadata": {
        "id": "a7c55b32548497b"
      },
      "source": [
        "## Vector Similarity\n",
        "\n",
        "The ability to measure vector similarity is crucial in machine learning and mathematics more broadly. The foundation for this measurement lies in the *dot product*, which serves as the foundation for many vector similarity metrics.\n",
        "\n",
        "One issue with the dot product, when used in isolation, is that it can take on any value and is therefore difficult to interpret in absolute terms. For example, if you know only that the dot product between two vectors is -3, then it’s unclear what that means without more context.\n",
        "\n",
        "To overcome this shortcoming, one common approach is to use **cosine similarity**, a normalized form of the dot product. You compute cosine similarity by taking the cosine of the angle between two vectors. In essence, you rearrange the cosine definition of the dot product from earlier to solve for `cos(θ)`. The equation for cosine similarity looks like this:\n",
        "\n",
        "<img src=\"cosine-similarity-graph.avif\" width=380>\n",
        "\n",
        "Cosine similarity disregards the magnitude of both vectors, forcing the calculation to lie between -1 and 1. This is a really nice property because it gives cosine similarity the following interpretations:\n",
        "\n",
        "* A value of 1 means the angle between the two vectors is 0 degrees. In other words, the two vectors are similar because they point in the exact same direction. Keep in mind this doesn’t mean that the vectors have the same magnitude.\n",
        "\n",
        "* A value of 0 means the angle between the two vectors is 90 degrees. In this case, the vectors are orthogonal and unrelated to each other.\n",
        "\n",
        "* A value of -1 means the angle between the two vectors is 180 degrees. This is an interesting case where the vectors are dissimilar because they point in opposite directions.\n",
        "\n",
        "In short, a cosine similarity of 1 means the vectors are similar, 0 means the vectors are unrelated, and -1 means the vectors are opposite. Any values in between represent varying degrees of similarity or dissimilarity.\n",
        "\n",
        "We used two-dimensional vectors because they’re straightforward to visualize, but keep in mind that everything covered so far applies to vectors of any dimension. In the next section, you’ll use the same cosine similarity calculation to compare vectors in high-dimensional vector spaces.\n",
        "\n",
        "You now have a feel for what vectors are and how you can assess their similarity. While there are many more vector concepts to learn about, you know enough to speak the language of embeddings and vector databases. In the next section, you’ll see how to convert words and sentences to vectors, a key prerequisite to text-based vector databases."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72d45cfe3a9d0120",
      "metadata": {
        "id": "72d45cfe3a9d0120"
      },
      "source": [
        "## Encode Objects in Embeddings\n",
        "\n",
        "The next step in your journey to understanding and using vector databases like *ChromaDB* is to get a feel for embeddings. **Embeddings** are a way to represent data such as words, text, images, and audio in a numerical format that computational algorithms can more easily process.\n",
        "\n",
        "More specifically, embeddings are dense vectors that characterize meaningful information about the objects that they encode. The most common kinds of embeddings are word and text embeddings, and that’s what you’ll focus on in this tutorial.\n",
        "\n",
        "### Word Embeddings\n",
        "A word embedding is a vector that captures the semantic meaning of word. Ideally, words that are semantically similar in natural language should have embeddings that are similar to each other in the encoded vector space. Analogously, words that are unrelated or opposite of one another should be further apart in the vector space.\n",
        "\n",
        "One of the best ways to conceptualize this idea is to plot example word vectors in two dimensions. Take a good look at this scatterplot:\n",
        "\n",
        "<img src=\"embedding-graph.avif\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4514cc1385b388d3",
      "metadata": {
        "id": "4514cc1385b388d3"
      },
      "source": [
        "This plot shows hand-crafted word embeddings plotted in two dimensions. Each point indicates where the word embedding’s tail lies. You’ll notice how related words are clustered together, while unrelated words are far from each other.\n",
        "\n",
        "As an example, the vehicle embeddings are far from the animal embeddings because there’s little semantic similarity between the two. On the other hand, the adjectives with positive connotations are relatively close to the fruits, with the delicious embedding being closest to the fruit embeddings.\n",
        "\n",
        "Because you’ll usually find the word delicious in contexts relating to food, it makes sense for the delicious embedding to have some similarity with both food embeddings and positive adjective embeddings.\n",
        "\n",
        "Word embeddings try to capture these semantic relationships for a large vocabulary of words, and as you might imagine, there are a lot of complex relationships to consider. This is why, in practice, word embeddings often require hundreds or thousands of dimensions to account for the complexities of human language.\n",
        "\n",
        "> Note: If you’re interested in how word embeddings are created, then check out the Word2vec and GloVe algorithms. These algorithms create static word embeddings like the ones that you’ll use later in this section, but there are other ways to create dynamic embeddings. For example, the model underlying most large language models (LLMs), including ChatGPT, creates word embeddings that change based on the context surrounding the word.\n",
        "\n",
        "You’re now ready to get started using word vectors in Python. For this, you’ll use the popular `spaCy` library, a general-purpose NLP library. To install `spaCy`, create a virtual environment, activate it, and run the following command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2974b5aef39e76a4",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-16T18:19:21.879209Z",
          "start_time": "2024-11-16T18:19:21.797868Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2974b5aef39e76a4",
        "outputId": "4b543d6a-0baf-4f2e-f638-f5ef50f72529"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd434fb4e86477",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-16T06:18:02.170640Z",
          "start_time": "2024-11-16T06:17:09.897122Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd434fb4e86477",
        "outputId": "cba2f467-907c-4dcf-9e7b-021577b39cd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.13.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b88024f356c3aae2",
      "metadata": {
        "id": "b88024f356c3aae2"
      },
      "source": [
        "After you’ve installed `spaCy`, you’ll also need to download a model that provides word embeddings, among other features. For this tutorial, you’ll want to install the medium or large English model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "225b9dd6ea2bf7fe",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-16T06:25:18.526175Z",
          "start_time": "2024-11-16T06:25:09.663254Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "225b9dd6ea2bf7fe",
        "outputId": "b50eb130-b2fc-46a6-d070-2ebf8547c9bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-md==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.7.1/en_core_web_md-3.7.1-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.13.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.2)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.7.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_md"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IuD-56VTt8rU"
      },
      "id": "IuD-56VTt8rU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d8b0d4727387671f",
      "metadata": {
        "id": "d8b0d4727387671f"
      },
      "source": [
        "SpaCy’s `en_core_web_md model` includes 20,000 pre-trained word embeddings. Each of these embeddings is a 300-dimensional vector, capturing semantic information about the corresponding word. This is more than enough for the examples that you’ll see next, but if you have the appetite for more word embeddings, then you can download the `en_core_web_lg model`, which has *514,000* embeddings.\n",
        "\n",
        "With `spaCy`’s medium or large English model installed, you’re ready to get started using word embeddings. It only takes a few lines of code to look up embeddings:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b945a863309531a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-16T18:23:58.524019Z",
          "start_time": "2024-11-16T18:23:55.582697Z"
        },
        "id": "6b945a863309531a"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48a5cd950cbe0d3f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-16T18:24:00.875574Z",
          "start_time": "2024-11-16T18:24:00.870382Z"
        },
        "id": "48a5cd950cbe0d3f"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('en_core_web_md')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f49f96d9b4ec929a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-16T06:25:53.863905Z",
          "start_time": "2024-11-16T06:25:53.860119Z"
        },
        "id": "f49f96d9b4ec929a"
      },
      "outputs": [],
      "source": [
        "dog_embedding = nlp.vocab['dog'].vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6831405063d0fae2",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-16T06:25:56.690774Z",
          "start_time": "2024-11-16T06:25:56.686030Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6831405063d0fae2",
        "outputId": "5e4c49e9-1a36-42e0-cd68-69e862b30b3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "dog_embedding.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33250e1b30d70995",
      "metadata": {
        "id": "33250e1b30d70995"
      },
      "source": [
        "You first import spacy and load the medium English model into an object called `nlp`. You then look up the embedding for the word dog with `nlp.vocab[\"dog\"].vector` and store it as `dog_embedding`. Calling `type(dog_embedding)` tells you that the embedding is a NumPy array, and `dog_embedding.shape` indicates that the embedding has 300 dimensions. Lastly, `dog_embedding[0:10]` shows the values of the first 10 dimensions.\n",
        "\n",
        "This is pretty neat! The `nlp.vocab` object allows you to find the word embedding for any word in the model’s vocabulary.\n",
        "\n",
        "You can now assess the similarity between word embeddings using metrics like cosine similarity. To do this, create a new function called `compute_cosine_similarity`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6a2bf5b92cd1d91",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-16T18:23:52.363619Z",
          "start_time": "2024-11-16T18:23:52.360107Z"
        },
        "id": "a6a2bf5b92cd1d91"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_cosine_similarity(u: np.ndarray, v: np.ndarray) -> float:\n",
        "    \"\"\"Compute the cosine similarity between two vectors\"\"\"\n",
        "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76380e1921307b82",
      "metadata": {
        "id": "76380e1921307b82"
      },
      "source": [
        "This function computes the cosine similarity between two NumPy arrays, `u` and `v`, using the definition discussed previously. You can pass word embeddings directly from `spaCy` into `compute_cosine_similarity()` to see how related they are:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97489ca70d66404a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-16T18:24:04.539330Z",
          "start_time": "2024-11-16T18:24:04.536412Z"
        },
        "id": "97489ca70d66404a"
      },
      "outputs": [],
      "source": [
        "dog_embedding = nlp.vocab[\"dog\"].vector\n",
        "cat_embedding = nlp.vocab[\"cat\"].vector\n",
        "apple_embedding = nlp.vocab[\"apple\"].vector\n",
        "tasty_embedding = nlp.vocab[\"tasty\"].vector\n",
        "delicious_embedding = nlp.vocab[\"delicious\"].vector\n",
        "truck_embedding = nlp.vocab[\"truck\"].vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16f569a5cd45b2ed",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-16T18:24:22.018555Z",
          "start_time": "2024-11-16T18:24:22.014951Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16f569a5cd45b2ed",
        "outputId": "c06d0a18-37b4-4354-acf7-d93a0f33f48c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8220817"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "compute_cosine_similarity(dog_embedding, cat_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "560696908091d250",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-16T18:25:57.044192Z",
          "start_time": "2024-11-16T18:25:57.040219Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "560696908091d250",
        "outputId": "95561aec-3cf8-49c1-86f5-7ace29e000b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.47355863"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "compute_cosine_similarity(apple_embedding, tasty_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "501dfa386c14dc8f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-16T18:26:00.991562Z",
          "start_time": "2024-11-16T18:26:00.987523Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "501dfa386c14dc8f",
        "outputId": "129af21c-348d-4814-a0f3-fbd1ba675f08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.84820914"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "compute_cosine_similarity(tasty_embedding, delicious_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1172db63d7cc2249",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-16T18:26:03.959024Z",
          "start_time": "2024-11-16T18:26:03.954995Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1172db63d7cc2249",
        "outputId": "63197746-36d8-4c01-f882-9ef36fb96963"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0897876"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "compute_cosine_similarity(delicious_embedding, truck_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "974908fce86a4517",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-16T18:26:08.308813Z",
          "start_time": "2024-11-16T18:26:08.304972Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "974908fce86a4517",
        "outputId": "65174b2a-6247-4b6a-82bb-1cba7eaa318d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25462714"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "compute_cosine_similarity(dog_embedding, truck_embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c36b2509cd58d4ea",
      "metadata": {
        "id": "c36b2509cd58d4ea"
      },
      "source": [
        "In this block, you import `spacy` and `compute_cosine_similarity()`, and you instantiate an `nlp` object using the medium-size English model. Next, you look up and store embeddings for six common words from the model’s vocabulary. By computing the cosine similarity between these embeddings, you get a sense for how the model views their semantic relationship. Here are some important observations about the similarity scores:\n",
        "\n",
        "* The cat and dog embeddings have a relatively high cosine similarity. This is likely because cats and dogs are common house pets, and you can find the word dog close to the word cat in English texts.\n",
        "\n",
        "* The delicious and tasty embeddings also have a high cosine similarity because they have almost the same meaning. However, unlike the dog and cat embeddings, delicious and tasty have similar word embeddings because you can use them interchangeably.\n",
        "\n",
        "* The delicious and apple embeddings have a moderate cosine similarity near 0.53. This is because delicious is a commonly used adjective to describe an apple. The reason that the cosine similarity isn’t higher in this case may be because apple and delicious aren’t always used in the same context. The word delicious can describe any food, not just apples.\n",
        "\n",
        "* The truck and delicious embeddings have a cosine similarity close to 0. As you might expect, truck and delicious aren’t words that commonly appear in the same context.\n",
        "\n",
        "Word embeddings are great for capturing the semantic relationships between words, but what if you wanted to take things to the next level and analyze the similarity between sentences or documents? It turns out you accomplish this with text embeddings, and these are the kinds of embeddings that you’ll most often store in vector databases. More on that in the next section."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a59f0f572412813",
      "metadata": {
        "id": "2a59f0f572412813"
      },
      "source": [
        "### Text Embeddings\n",
        "Text embeddings encode information about sentences and documents, not just individual words, into vectors. This allows you to compare larger bodies of text to each other just like you did with word vectors. Because they encode more information than a single word embedding, text embeddings are a more powerful representation of information.\n",
        "\n",
        "Text embeddings are typically the fundamental objects stored in vector databases like `ChromaDB`, and in this section, you’ll learn how to create and compare them.\n",
        "\n",
        "> Note: The best text embedding models are built using transformers, which leverage a mechanism known as attention. To oversimplify things, the attention mechanism helps create context-specific word embeddings that fuse into text embeddings.\n",
        "\n",
        "The most efficient way to generate text embeddings is to use pretrained models. These models vary in size, but they’re all typically trained on a large corpus of text, enabling them to pick up on complex semantic relationships. The `SentenceTransformers` library in Python is one of the best tools for this. You can install `sentence-transformers` with the following command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0694557eac1ab4c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-16T09:16:54.398686Z",
          "start_time": "2024-11-16T09:16:52.966527Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0694557eac1ab4c",
        "outputId": "b2f3e473-90ae-43f2-afcb-a2c6fecb71d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.46.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.26.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e62be0f2777883a",
      "metadata": {
        "id": "4e62be0f2777883a"
      },
      "source": [
        "Generating text embeddings with `SentenceTransformers` is just as straightforward as using word vectors in spaCy. Here’s an example to get you started:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf1e622745be93df",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-16T18:46:58.994843Z",
          "start_time": "2024-11-16T18:46:57.193312Z"
        },
        "id": "bf1e622745be93df"
      },
      "outputs": [],
      "source": [
        "# Install the sentence-transformers package\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "texts = [\n",
        "    \"The canine barked loudly.\",\n",
        "    \"The dog made a noisy bark.\",\n",
        "    \"He ate a lot of pizza.\",\n",
        "    \"He devoured a large quantity of pizza pie.\",\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcdbe12cf44799ad",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-16T18:47:08.225682Z",
          "start_time": "2024-11-16T18:47:08.221952Z"
        },
        "id": "bcdbe12cf44799ad"
      },
      "outputs": [],
      "source": [
        "text_embeddings = model.encode(texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce6f0e838993782e",
      "metadata": {
        "id": "ce6f0e838993782e"
      },
      "source": [
        "You first import the `SentenceTransformer` class and load the `\"all-MiniLM-L6-v2\"` model into an object called `model`. This is one of the smallest pretrained models available, but it’s a great one to start with.\n",
        "\n",
        "> Note: The first time you use a model in SentenceTransformers, you’ll automatically download and save it in your environment. The initial download will take a few seconds depending on how large the model is, but after that, the model should load quickly.\n",
        "\n",
        "Next, you define a list of sentences and call `model.encode(texts)` to create the corresponding text embeddings. Notice that `text_embeddings` is a NumPy array with the shape `(4, 384)`, which means that it has 4 rows and 384 columns. This is because you encoded 4 texts, and `all-MiniLM-L6-v2` generates 384-dimensional embeddings.\n",
        "\n",
        "Here's a breakdown of what happens behind the scenes:\n",
        "\n",
        "1. Sentence Transformer Initialization:\n",
        "\n",
        "    * When you create a SentenceTransformer with `'all-MiniLM-L6-v2'`, you're loading a pre-trained model. This specific model is a smaller version of the \"all-mpnet-base-v2\" model, fine-tuned for sentence similarity tasks.\n",
        "    * This pre-trained model already has knowledge of language and relationships between words, acquired through training on a massive dataset.\n",
        "\n",
        "2. Text Processing:\n",
        "\n",
        "    * Your input texts are tokenized. This means they are split into individual words or sub-word units.\n",
        "    * These tokens are then converted into numerical representations that the model can understand.\n",
        "\n",
        "3. Transformer Encoding:\n",
        "\n",
        "    * The tokenized input is fed into the transformer model (MiniLM in this case).\n",
        "    * The transformer processes the input sequence through multiple layers of self-attention and feed-forward networks. This allows it to capture complex relationships between words and understand the overall meaning of the sentence.\n",
        "    * The output of the transformer is a sequence of contextualized word embeddings. Each word's embedding now represents its meaning within the context of the entire sentence.\n",
        "\n",
        "4. Pooling:\n",
        "\n",
        "    * To obtain a single fixed-length sentence embedding, a pooling operation is applied to the sequence of word embeddings. Common pooling methods include:\n",
        "    * Mean Pooling: Averaging all the word embeddings.\n",
        "    * Max Pooling: Taking the maximum value for each dimension across all word embeddings.\n",
        "\n",
        "5. Output:\n",
        "\n",
        "    * The `model.encode(texts)` function returns a NumPy array (`text_embeddings`) where each row represents a sentence, and each column represents a dimension in the embedding space. In this case, you'll have a 4x384 array, as you encoded 4 sentences, and `'all-MiniLM-L6-v2'` produces 384-dimensional embeddings.\n",
        "\n",
        "In essence, the SentenceTransformer model takes your text, breaks it down, understands its meaning using the transformer, and then condenses this understanding into a dense vector representation. This vector captures the semantic essence of the input text.\n",
        "\n",
        "\n",
        "While all the texts in this example are single sentences, you can encode longer texts up to a specified word length. For example, `all-MiniLM-L6-v2` encodes texts up to 256 words. It’ll truncate any text longer than this.\n",
        "\n",
        "You now have a text embedding for all four texts, and just like with word embeddings, you can compare them using cosine similarity:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84e3ff56ea3ca9a7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-16T18:50:42.764191Z",
          "start_time": "2024-11-16T18:50:42.754387Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84e3ff56ea3ca9a7",
        "outputId": "98a98c51-50f6-4c2f-e676-58be1879ad3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'The canine barked loudly.': array([ 3.49791571e-02, -6.75668102e-03,  4.14040610e-02,  1.02993436e-01,\n",
              "         1.22451980e-03, -5.86038232e-02,  6.07008673e-03, -5.44335432e-02,\n",
              "        -5.31257363e-03, -2.54312195e-02,  3.07495072e-02, -2.83202007e-02,\n",
              "         3.18731405e-02,  4.32385169e-02,  2.42533647e-02,  2.52667833e-02,\n",
              "         4.16827984e-02,  1.80074181e-02,  4.40936871e-02, -1.06606603e-01,\n",
              "         4.04250255e-04,  7.75528774e-02,  4.00948524e-02, -1.38763273e-02,\n",
              "        -4.20556292e-02, -7.21510686e-03,  2.03238986e-02, -8.29127803e-02,\n",
              "         2.65511367e-02, -1.30723817e-02,  2.53968723e-02, -9.90436748e-02,\n",
              "         1.84984896e-02,  1.03864567e-02, -4.68488457e-03, -2.48143300e-02,\n",
              "         6.21577986e-02,  4.55181152e-02,  9.23830941e-02,  2.91003305e-02,\n",
              "         3.50559987e-02,  4.20786291e-02, -1.08965877e-02, -8.03956538e-02,\n",
              "        -9.96238440e-02, -1.85392443e-02, -4.03281748e-02, -5.50757460e-02,\n",
              "         4.68578301e-02, -7.46965855e-02, -3.26624326e-02, -1.32077774e-02,\n",
              "         3.71940583e-02, -4.52731960e-02, -3.72452103e-02, -3.23356651e-02,\n",
              "         3.40739973e-02,  4.98803239e-03,  4.77956533e-02, -5.14155952e-04,\n",
              "        -4.95912433e-02,  3.54585052e-02,  1.63054019e-02,  4.99976985e-02,\n",
              "         6.57187924e-02, -4.54585999e-02, -1.59692932e-02,  1.51029511e-04,\n",
              "        -8.82789958e-03,  9.26815420e-02,  1.00707874e-01, -3.21482471e-03,\n",
              "         1.69778038e-02, -6.71478510e-02, -7.49395369e-03,  3.31438705e-02,\n",
              "        -3.71061265e-02,  2.14747265e-02,  9.68511328e-02,  1.07789924e-02,\n",
              "        -1.82104800e-02, -5.15457466e-02, -4.53374870e-02,  8.53087811e-04,\n",
              "         4.39502969e-02,  4.83792312e-02,  3.80958281e-02,  2.26494148e-02,\n",
              "        -1.21726327e-01,  2.21701991e-02, -1.76799074e-02, -1.27230838e-01,\n",
              "        -3.86364050e-02,  7.25303292e-02, -3.88306119e-02, -4.74938713e-02,\n",
              "        -5.99644333e-03,  2.72068940e-03, -1.87153183e-02,  2.82840449e-02,\n",
              "        -4.15693782e-02, -1.94578245e-02, -2.06768531e-02, -3.57713066e-02,\n",
              "        -1.14480928e-02,  2.32560243e-02, -5.64662181e-02,  5.25427610e-02,\n",
              "         3.99353361e-04,  5.86641207e-02, -5.76029047e-02, -3.30359973e-02,\n",
              "        -6.17379583e-02,  3.49112712e-02,  8.64982009e-02,  7.42238201e-03,\n",
              "        -2.89231800e-02, -5.50306216e-02,  4.77626082e-03, -1.21761234e-02,\n",
              "         9.58383083e-02,  8.91653541e-03, -1.00439422e-01, -2.61079203e-02,\n",
              "         5.31465746e-02,  8.80058017e-03,  2.67381817e-02, -6.72341112e-33,\n",
              "         4.50487286e-02,  9.41049755e-02, -8.96747187e-02, -7.89225996e-02,\n",
              "        -1.27958395e-02,  2.01872271e-02,  2.52948422e-02, -5.31004034e-02,\n",
              "        -2.07538586e-02,  4.72649783e-02, -1.99500937e-02,  1.78839024e-02,\n",
              "         3.37951332e-02, -2.32262854e-02,  1.14114080e-02, -7.00885430e-02,\n",
              "         1.68608828e-03,  3.82600017e-02,  3.19416933e-02, -1.14684105e-02,\n",
              "        -4.56700064e-02,  6.13348708e-02, -3.52205448e-02,  1.64232161e-02,\n",
              "         7.02831149e-02, -2.39977911e-02, -1.31355822e-02, -7.23215789e-02,\n",
              "        -1.89248938e-02,  4.03561704e-02,  3.07045374e-02, -7.47242756e-03,\n",
              "         4.99482751e-02,  6.98730573e-02, -5.47792800e-02, -2.61165909e-02,\n",
              "        -5.62020615e-02, -4.26022969e-02, -2.63319351e-02,  5.37992455e-02,\n",
              "         6.45797253e-02, -1.51055399e-02,  2.87873298e-03,  1.68787912e-02,\n",
              "         6.19353866e-03,  4.26845215e-02, -1.49703875e-01, -8.51820107e-04,\n",
              "         4.11377614e-03, -9.00843926e-03,  7.42207989e-02,  5.46593731e-03,\n",
              "         1.03477776e-01, -1.13448929e-02,  4.48630452e-02,  2.86483597e-02,\n",
              "         8.79209489e-02, -4.50341702e-02,  3.26917246e-02,  5.19009084e-02,\n",
              "         4.23861817e-02, -2.19428074e-02,  8.96616727e-02, -2.86305286e-02,\n",
              "         1.17763206e-01, -1.00669049e-01, -5.22341654e-02, -5.30977501e-03,\n",
              "        -1.38207125e-02,  4.20471020e-02,  2.80047432e-02, -1.86973251e-02,\n",
              "         1.46601461e-02, -5.52729405e-02,  4.02670959e-03, -1.31499134e-02,\n",
              "         5.01409546e-02,  3.45112383e-02,  4.74818200e-02, -9.05419216e-02,\n",
              "        -2.82210968e-02, -1.05030024e-02,  3.04604275e-03,  1.03453070e-01,\n",
              "         4.26170565e-02, -3.26306530e-04, -6.63543940e-02,  5.53385960e-03,\n",
              "        -7.60712698e-02,  8.78058970e-02,  3.51835415e-02, -4.54492718e-02,\n",
              "        -2.61129253e-02,  1.59941753e-03, -1.14710024e-02,  3.23137556e-33,\n",
              "         9.35243964e-02,  1.32463172e-01,  3.16832736e-02,  1.05784191e-02,\n",
              "        -1.19959354e-01,  8.16848204e-02, -8.57377797e-02,  6.33697361e-02,\n",
              "        -1.00250952e-01,  2.67628487e-02, -3.94731294e-03,  2.14634612e-02,\n",
              "        -3.51218437e-03,  2.71627512e-02,  9.43034049e-03,  2.12833118e-02,\n",
              "         9.87256225e-03,  4.97911945e-02,  3.78859346e-03, -8.22689608e-02,\n",
              "        -7.72626847e-02, -8.34106002e-03,  7.31566101e-02,  2.87767015e-02,\n",
              "         4.71141469e-03, -5.26334122e-02, -2.59987004e-02, -3.36663313e-02,\n",
              "         2.00055763e-02, -1.19840927e-01, -4.22885269e-02,  8.12905096e-03,\n",
              "        -1.06343059e-02, -1.43342717e-02,  4.60389219e-02,  2.89380401e-02,\n",
              "         4.71440889e-02,  3.98272239e-02,  5.37640825e-02, -3.80291902e-02,\n",
              "        -4.51476611e-02,  2.07973607e-02, -4.07590112e-03,  4.40048836e-02,\n",
              "         2.42993627e-02,  5.61707430e-02,  4.28756773e-02, -1.06686473e-01,\n",
              "        -1.82309952e-02,  2.28411332e-02,  1.48025081e-02, -9.92471469e-04,\n",
              "         7.82330707e-02,  3.17499451e-02, -1.06947478e-02,  1.53917441e-04,\n",
              "        -2.38673892e-02, -2.77566016e-02, -4.87245321e-02, -7.46137649e-02,\n",
              "         2.83362549e-02,  5.14943264e-02,  1.14552751e-02,  7.13367909e-02,\n",
              "        -4.82431240e-02, -9.28291231e-02, -2.62861382e-02, -7.55733997e-02,\n",
              "         7.46774971e-02, -7.01373145e-02,  2.50171142e-04,  8.60192161e-03,\n",
              "        -6.11053221e-02,  1.19149359e-02, -1.85851697e-02,  4.96095791e-02,\n",
              "         3.15160793e-03, -9.10456479e-02,  1.41933141e-02, -1.12998011e-02,\n",
              "         1.35468773e-03, -1.01192435e-02, -6.03960156e-02,  2.26892345e-03,\n",
              "        -1.10644959e-02, -6.22596731e-03,  1.29281543e-02,  7.65993372e-02,\n",
              "        -6.84069842e-03, -1.19521981e-02,  2.00846605e-02,  1.24936551e-01,\n",
              "         1.97992157e-02, -2.22184528e-02, -1.01593090e-02, -1.47770862e-08,\n",
              "        -1.11985318e-01,  1.05671892e-02, -6.98929876e-02, -6.45796508e-02,\n",
              "         1.03712179e-01,  5.82960695e-02, -1.59069728e-02,  2.50491919e-03,\n",
              "        -9.00611207e-02, -4.51658443e-02, -7.17832288e-03, -9.99343619e-02,\n",
              "        -6.06740825e-02,  1.97815355e-02, -1.87999643e-02,  4.68404852e-02,\n",
              "        -3.62138450e-02,  2.63369754e-02,  3.84071730e-02,  4.68121991e-02,\n",
              "        -8.09929967e-02,  5.73895164e-02,  1.68956202e-02, -1.37985488e-02,\n",
              "        -5.54976277e-02, -1.41494116e-02, -2.14675050e-02,  1.96550153e-02,\n",
              "        -4.12351526e-02,  6.10172786e-02, -1.92820914e-02,  6.06232509e-02,\n",
              "        -7.60167167e-02, -6.55071735e-02, -1.14772983e-01,  1.51120184e-03,\n",
              "         3.75602283e-02, -9.28650722e-02,  1.80420317e-02, -6.76721409e-02,\n",
              "         2.43311971e-02,  1.01555720e-01, -2.95560025e-02, -2.71554012e-02,\n",
              "         8.05694163e-02,  4.22568098e-02,  7.00804368e-02, -1.09220058e-01,\n",
              "        -1.86684206e-02, -2.72443928e-02, -1.39157340e-01,  4.88801450e-02,\n",
              "        -1.03247156e-02, -1.95265021e-02, -4.42630686e-02,  4.36359793e-02,\n",
              "        -5.03484793e-02, -1.01789720e-01,  3.19452435e-02,  1.81268174e-02,\n",
              "         8.51252526e-02,  4.71372567e-02,  1.52890319e-02,  7.19901919e-02],\n",
              "       dtype=float32),\n",
              " 'The dog made a noisy bark.': array([ 2.74259280e-02, -9.04441718e-03,  5.62751815e-02,  1.21323131e-01,\n",
              "        -1.04276249e-02, -4.95569631e-02,  3.35291959e-02, -6.16520569e-02,\n",
              "         1.79824606e-02, -3.64443846e-02, -2.07194295e-02, -1.99261513e-02,\n",
              "         7.01246262e-02,  8.11340520e-04, -4.09318432e-02,  3.61471549e-02,\n",
              "        -3.57056521e-02,  2.30546948e-02,  3.49107459e-02, -9.34807211e-02,\n",
              "        -3.51587273e-02,  8.32249150e-02,  3.84880453e-02,  2.38407068e-02,\n",
              "        -1.25940982e-02,  1.60717443e-02,  1.84974223e-02, -1.00016922e-01,\n",
              "         1.42968073e-02, -1.31532401e-02,  3.09071802e-02, -6.06710650e-02,\n",
              "         2.55464867e-04,  2.73937583e-02, -5.48334280e-03, -5.93699925e-02,\n",
              "         5.21515161e-02,  6.15221336e-02,  9.61586535e-02,  3.29952016e-02,\n",
              "         2.25335434e-02,  9.89074856e-02,  4.91049774e-02, -1.04789741e-01,\n",
              "        -4.70844992e-02, -3.82345691e-02, -6.32607192e-02, -1.11186765e-01,\n",
              "         5.93139827e-02, -3.62740830e-02, -4.19550538e-02, -2.28021573e-02,\n",
              "         1.41875017e-02, -6.45706132e-02, -1.44902728e-02, -4.97249141e-02,\n",
              "         1.12334024e-02,  4.47232276e-02,  1.04040978e-02,  6.12731948e-02,\n",
              "        -6.68340223e-03,  3.35305966e-02,  3.58899892e-03,  5.85140102e-02,\n",
              "         7.87945613e-02,  7.88136292e-03, -7.93291554e-02, -5.02193673e-03,\n",
              "        -2.19250564e-02,  1.05934791e-01,  4.73757945e-02, -6.30895095e-03,\n",
              "         1.32283401e-02, -3.62446941e-02,  1.06333233e-02, -1.19992057e-02,\n",
              "        -3.18079069e-02,  2.83635762e-02,  1.21953152e-01,  1.96906552e-02,\n",
              "        -6.16602749e-02, -2.89183278e-02, -7.90910572e-02, -2.70355940e-02,\n",
              "         8.84187315e-03, -1.53635703e-02,  9.07600820e-02,  9.93173290e-03,\n",
              "        -9.15838778e-02,  2.90635042e-02,  2.46681157e-03, -1.08034767e-01,\n",
              "        -1.17821313e-01,  8.80571157e-02, -8.31940584e-03, -2.73123221e-03,\n",
              "        -2.40816996e-02,  1.90812275e-02,  2.75516715e-02,  3.03357523e-02,\n",
              "        -1.46725550e-02,  2.67234445e-02, -2.87156701e-02, -1.17422841e-01,\n",
              "         9.38577671e-03,  5.00610471e-02, -5.18167317e-02,  4.70973253e-02,\n",
              "        -4.77265865e-02,  6.95383921e-02, -8.31270590e-02,  3.23481262e-02,\n",
              "        -6.15178347e-02,  9.96171981e-02,  9.11031142e-02,  4.20974307e-02,\n",
              "        -7.40235439e-03, -6.95711300e-02, -5.56363203e-02, -3.97131182e-02,\n",
              "         1.10034108e-01, -5.53374086e-03, -1.08695135e-01, -1.49595570e-02,\n",
              "         5.09515032e-02, -1.91005319e-02,  3.03884819e-02, -7.73179573e-33,\n",
              "         5.29232211e-02,  1.96657982e-02, -5.59269562e-02, -5.45697287e-02,\n",
              "         6.49698749e-02,  4.34194170e-02, -3.01446915e-02, -5.65076508e-02,\n",
              "        -5.65784387e-02,  2.47021466e-02,  1.25214616e-02, -5.04072644e-02,\n",
              "         2.82600671e-02, -4.40758877e-02,  6.80142045e-02, -3.82036567e-02,\n",
              "        -3.69878225e-02,  1.72418114e-02,  4.63411883e-02, -4.79227379e-02,\n",
              "        -4.82829921e-02,  8.31470490e-02, -5.65267215e-03,  2.55295821e-02,\n",
              "         7.64106438e-02,  2.35562995e-02,  1.61680896e-02, -9.20197070e-02,\n",
              "        -1.11447591e-02,  4.06439193e-02,  3.04839830e-03, -1.18831638e-02,\n",
              "         4.28202339e-02,  4.08961214e-02, -2.03025807e-02,  9.82289109e-03,\n",
              "        -2.34365147e-02, -3.41930874e-02, -2.76835784e-02,  8.86544678e-03,\n",
              "         8.64278078e-02, -1.39147285e-02,  2.22411528e-02, -5.63035952e-03,\n",
              "        -1.35881663e-03,  5.61052859e-02, -1.57082543e-01,  1.00223552e-02,\n",
              "         3.99314053e-03, -3.02038947e-03,  4.94207367e-02,  3.08906976e-02,\n",
              "         1.21621087e-01, -2.63068303e-02,  2.85452679e-02,  4.63142581e-02,\n",
              "         1.40889108e-01, -1.65104941e-02,  6.13747798e-02,  3.13610882e-02,\n",
              "         7.67299086e-02, -1.41723203e-02,  7.70885423e-02, -5.16484268e-02,\n",
              "         1.25430867e-01, -6.46974817e-02, -3.45405377e-02, -2.06340421e-02,\n",
              "        -4.30357791e-02, -4.50546518e-02,  2.00385787e-02, -4.77797836e-02,\n",
              "        -4.05723639e-02, -4.62584104e-03, -6.94686372e-04, -2.47518793e-02,\n",
              "        -2.87352093e-02,  1.80045981e-02,  1.76512972e-02, -9.31583717e-02,\n",
              "        -3.31547931e-02, -5.07453158e-02, -3.49717401e-02,  6.31276146e-02,\n",
              "        -1.31582217e-02,  8.59321654e-03, -5.52091971e-02,  5.84569573e-02,\n",
              "        -6.17871918e-02,  6.98991492e-02, -7.52351945e-03, -2.49978676e-02,\n",
              "         3.64942327e-02, -1.30463690e-02, -2.21728887e-02,  3.68059293e-33,\n",
              "        -1.62227247e-02,  6.81965500e-02,  3.57585289e-02,  3.35794203e-02,\n",
              "        -1.03877246e-01,  7.19181495e-03, -8.67283344e-02,  4.44968306e-02,\n",
              "        -2.02704910e-02,  3.96005511e-02,  2.48284694e-02, -3.56069244e-02,\n",
              "         1.60325617e-02,  5.06091677e-02, -3.74581176e-03,  4.41149157e-03,\n",
              "         1.68227628e-02,  7.73146302e-02,  5.56289144e-02, -1.70528248e-03,\n",
              "        -3.12598273e-02,  5.44681549e-02,  4.18302417e-02,  4.13644388e-02,\n",
              "        -5.15872100e-03,  9.89023224e-03, -1.27017368e-02,  5.97596820e-03,\n",
              "         1.20538287e-02, -9.98690799e-02, -1.94013771e-02, -1.08783608e-02,\n",
              "        -4.16313000e-02, -6.36916310e-02,  1.84344407e-02,  4.74567376e-02,\n",
              "         4.22812775e-02, -4.85996269e-02,  5.04240803e-02, -3.01106349e-02,\n",
              "        -5.89335104e-03, -3.81359272e-03,  8.68287811e-04, -1.48479966e-02,\n",
              "         4.99400049e-02,  5.24117686e-02,  1.09485658e-02, -5.82256876e-02,\n",
              "         2.16779463e-05, -1.18528516e-03,  7.31905401e-02,  4.53608595e-02,\n",
              "         8.19102526e-02,  6.55627102e-02, -3.58216576e-02, -2.01678090e-02,\n",
              "        -3.48085836e-02, -4.16526608e-02,  7.19819637e-03, -4.23423350e-02,\n",
              "        -4.92508858e-02,  4.00584042e-02,  3.35351704e-03, -5.18672578e-02,\n",
              "        -7.34295622e-02, -1.02519475e-01, -3.85846868e-02, -4.11145501e-02,\n",
              "         3.33313271e-02, -1.06801078e-01,  4.72768731e-02,  4.80667688e-02,\n",
              "        -8.44318345e-02,  8.16756412e-02, -3.28230709e-02,  6.61896765e-02,\n",
              "        -3.17428447e-02, -1.24894597e-01,  8.75756424e-03,  1.95865333e-02,\n",
              "        -3.57226729e-02, -1.83851905e-02, -4.53396775e-02,  6.62459359e-02,\n",
              "        -8.50409921e-03, -4.50533703e-02,  1.84695795e-02,  2.49176882e-02,\n",
              "        -3.07217706e-03,  1.57754426e-03,  3.25696543e-02,  8.67444053e-02,\n",
              "         5.34537360e-02, -1.51519580e-02, -3.29024754e-02, -1.69534076e-08,\n",
              "        -1.13397479e-01, -1.87009815e-02, -5.99730387e-02, -4.46728505e-02,\n",
              "         8.10324326e-02,  2.52647861e-03,  3.46847847e-02, -6.44818507e-03,\n",
              "        -6.38364330e-02, -3.85272801e-02, -2.03960389e-02, -6.12713061e-02,\n",
              "        -9.20535326e-02,  4.58389446e-02, -4.03709300e-02,  3.48203145e-02,\n",
              "        -2.41343863e-02,  8.02158266e-02,  6.27703592e-02, -3.82902287e-03,\n",
              "         3.79597135e-02,  1.91692505e-02, -5.11755049e-03, -1.54525822e-03,\n",
              "        -6.14508018e-02, -3.35329995e-02,  1.61779076e-02,  1.65288337e-02,\n",
              "        -7.87945017e-02,  3.25419679e-02,  9.96017945e-04,  8.56890157e-02,\n",
              "        -2.72767469e-02, -1.93630867e-02, -1.06034383e-01, -2.29185633e-02,\n",
              "         5.22260070e-02, -9.75217894e-02,  1.56839062e-02, -4.84569483e-02,\n",
              "         1.11594042e-02,  9.28701609e-02, -5.21217473e-02, -5.53028695e-02,\n",
              "         5.03893718e-02,  3.50951552e-02,  3.07169743e-02, -8.47659484e-02,\n",
              "        -1.92526821e-02,  3.39042060e-02, -5.72429150e-02,  7.54692852e-02,\n",
              "         3.36729027e-02, -7.24850371e-02, -1.19246189e-02,  1.41820572e-02,\n",
              "        -1.80851426e-02, -8.26931894e-02,  1.13832308e-02, -1.75760482e-02,\n",
              "         3.43027562e-02,  3.38293836e-02,  4.85875569e-02,  6.84804395e-02],\n",
              "       dtype=float32),\n",
              " 'He ate a lot of pizza.': array([ 3.61603349e-02,  1.14232793e-01,  1.29378010e-02,  8.86897445e-02,\n",
              "        -1.21728815e-01,  1.50230397e-02,  7.40128979e-02,  6.22213967e-02,\n",
              "        -5.00958227e-02, -9.08880308e-02,  3.02682128e-02, -5.70342317e-02,\n",
              "         2.31086276e-02,  1.25391856e-02,  1.54673094e-02, -8.23909268e-02,\n",
              "         6.11433499e-02,  2.59660110e-02, -1.57333650e-02, -3.18747349e-02,\n",
              "        -2.04908829e-02, -1.63138416e-02,  5.20412289e-02, -2.67430972e-02,\n",
              "         1.07924566e-02,  4.47114781e-02,  4.03223634e-02, -3.14871594e-02,\n",
              "        -2.49732882e-02, -2.82864552e-02,  1.20288692e-02,  5.54439351e-02,\n",
              "         5.11469729e-02, -2.81982850e-02,  1.91511102e-02,  2.22881716e-02,\n",
              "         5.77669479e-02, -1.97187904e-02,  5.43728806e-02,  1.29812304e-02,\n",
              "         6.10886402e-02,  5.80233056e-04,  2.63866503e-02, -7.06304912e-04,\n",
              "        -2.46728342e-02, -6.23255186e-02, -5.44144846e-02, -1.63298361e-02,\n",
              "         9.63090211e-02,  5.65688685e-02, -9.59091112e-02,  5.98033331e-03,\n",
              "         2.80722529e-02, -1.12719394e-01,  2.84307357e-02, -3.18335742e-02,\n",
              "         5.15368544e-02,  4.97500002e-02, -1.98984184e-04, -3.08236144e-02,\n",
              "        -4.36762124e-02, -6.47904426e-02, -1.59193035e-02,  7.06115067e-02,\n",
              "         5.40465536e-03, -3.65317427e-02, -4.08884957e-02, -6.64177909e-02,\n",
              "        -7.54308105e-02,  8.52727965e-02,  8.16341117e-03,  4.03440893e-02,\n",
              "        -3.29501950e-03, -7.17236176e-02, -2.45007351e-02, -6.21699132e-02,\n",
              "        -2.28637340e-03, -7.11046085e-02,  9.45620332e-03, -3.42884809e-02,\n",
              "         2.32944451e-02, -2.89135464e-02, -8.00108686e-02, -2.25731591e-03,\n",
              "         2.92050894e-02,  4.73138690e-02, -1.27458656e-02,  1.39727388e-02,\n",
              "        -1.22758530e-01,  6.33352995e-02,  2.70954799e-02, -5.11602834e-02,\n",
              "        -5.56246145e-03,  5.84720820e-03, -4.57954183e-02,  6.01846837e-02,\n",
              "        -4.59948890e-02, -5.17566614e-02, -1.99489817e-02,  6.73016086e-02,\n",
              "         3.56749967e-02,  3.84229794e-02,  7.90192187e-02, -2.97828205e-03,\n",
              "         1.22527583e-02,  1.55950021e-02,  9.13173705e-03,  7.39835128e-02,\n",
              "         3.05086171e-04, -1.02077601e-02, -4.16276939e-02, -2.39051469e-02,\n",
              "         1.41659901e-02, -1.71711314e-02,  1.90093033e-02,  6.06753863e-03,\n",
              "         7.49287233e-02, -2.28564534e-02, -8.38237032e-02,  4.18950878e-02,\n",
              "         1.31958881e-02,  7.81580433e-03, -5.59784435e-02,  4.87929396e-02,\n",
              "        -6.32047802e-02, -3.10773831e-02,  6.46167342e-03, -6.73630042e-33,\n",
              "         5.57096973e-02, -5.13744168e-02,  2.13825274e-02,  3.61394063e-02,\n",
              "         3.97479087e-02,  5.78113236e-02,  2.69072335e-02, -1.41154500e-02,\n",
              "         1.77262519e-02, -1.95985083e-02, -1.34976199e-02, -3.15119177e-02,\n",
              "        -2.46730093e-02,  8.32409933e-02, -1.87091194e-02,  6.79198280e-02,\n",
              "        -3.21146958e-02,  3.03567592e-02,  7.90825039e-02, -4.30359244e-02,\n",
              "         4.15307917e-02, -8.08592439e-02,  1.27578024e-02,  3.93755920e-02,\n",
              "         1.50906919e-02,  4.19120081e-02, -6.77413912e-03, -1.78497774e-03,\n",
              "        -3.90101671e-02,  1.05612604e-02,  2.71234624e-02,  7.67329708e-02,\n",
              "        -1.03581836e-03,  5.23212478e-02,  1.18801408e-01,  5.15248328e-02,\n",
              "        -2.80443560e-02,  1.11478381e-02, -7.88926259e-02,  6.93059340e-03,\n",
              "         2.73589492e-02,  4.03734259e-02,  3.22925858e-02, -2.09625978e-02,\n",
              "        -1.30847126e-01,  2.66447589e-02, -2.98764389e-02,  5.84551357e-02,\n",
              "         4.46884595e-02,  1.97087284e-02,  8.64103287e-02, -2.79995855e-02,\n",
              "         3.04029454e-02, -4.74383757e-02, -4.17111814e-02, -1.15792714e-02,\n",
              "         1.53498007e-02,  3.21947262e-02,  2.44364254e-02,  6.67152032e-02,\n",
              "         8.12997371e-02,  6.88617006e-02,  1.55963823e-02,  6.48462772e-02,\n",
              "        -1.13553084e-01,  5.97219495e-03, -1.80604588e-02, -1.73451547e-02,\n",
              "        -7.62768313e-02,  6.35639504e-02,  2.52159294e-02, -4.58419472e-02,\n",
              "         3.02288216e-02, -6.91020861e-02, -7.23386332e-02, -3.98956053e-02,\n",
              "        -9.07497481e-02, -3.59587595e-02, -8.41429904e-02,  1.45898750e-02,\n",
              "         8.74734744e-02, -4.71300110e-02,  1.13862514e-01, -6.63921684e-02,\n",
              "        -4.30841930e-02,  6.56455010e-02,  1.39978472e-02, -4.17417809e-02,\n",
              "         5.12635745e-02,  2.96365153e-02, -1.75620988e-02, -4.62364480e-02,\n",
              "         2.95977294e-02, -1.02829099e-01, -7.19026700e-02,  2.89007610e-33,\n",
              "        -8.49818513e-02,  8.79525840e-02,  5.27999550e-02, -1.16891386e-02,\n",
              "        -4.19352241e-02, -3.09592150e-02, -7.98022747e-02,  2.49801874e-02,\n",
              "         5.09894779e-03, -8.53249431e-02,  2.38830019e-02,  2.86634522e-03,\n",
              "         1.32546470e-01, -3.14968526e-02,  4.21174914e-02,  7.03983754e-02,\n",
              "         5.09357266e-02,  5.08152619e-02, -2.17298884e-02,  4.61699180e-02,\n",
              "        -2.64035035e-02, -9.88512784e-02, -1.75323877e-02,  6.73264563e-02,\n",
              "        -2.95089595e-02,  5.53251468e-02, -4.70563509e-02,  2.89621111e-02,\n",
              "        -7.69109353e-02,  9.55395680e-03, -7.51392636e-03, -1.28744021e-02,\n",
              "         5.73464110e-03,  6.05526054e-03, -2.16744859e-02,  1.16754614e-01,\n",
              "        -5.20795435e-02,  2.50335783e-02,  4.40300591e-02, -6.46399930e-02,\n",
              "        -6.19536126e-03, -8.10187832e-02,  7.73347393e-02,  1.07621863e-01,\n",
              "         4.55544144e-02, -2.00005602e-02, -3.56333405e-02, -8.16254169e-02,\n",
              "        -2.18465533e-02,  4.00900915e-02, -5.34479320e-02,  1.46949349e-03,\n",
              "        -2.34805904e-02,  7.25631714e-02,  8.38781241e-03,  3.22777480e-02,\n",
              "        -8.79846811e-02,  3.76924723e-02, -2.02784967e-02, -9.39618573e-02,\n",
              "        -1.09032787e-01, -4.09692042e-02, -2.31783893e-02,  6.89604059e-02,\n",
              "         3.78726497e-02, -2.42294816e-04, -2.30397973e-02, -8.54871571e-02,\n",
              "        -7.34789446e-02,  2.77228672e-02,  1.70245375e-02,  3.55293602e-02,\n",
              "        -6.31541759e-03,  2.52148174e-02, -9.77884084e-02,  2.34449413e-02,\n",
              "        -1.14425018e-01,  1.06382817e-02, -2.87435707e-02,  7.02041527e-03,\n",
              "        -6.06274754e-02, -9.25402120e-02, -3.78708132e-02, -8.46769474e-03,\n",
              "        -4.05156463e-02, -2.97080316e-02, -4.31832066e-03, -9.98194665e-02,\n",
              "        -5.19283265e-02,  4.01676968e-02,  2.04862021e-02, -1.22352177e-02,\n",
              "         7.11581782e-02, -3.20712589e-02,  4.12018597e-02, -1.68813070e-08,\n",
              "         9.81871504e-03, -3.46517079e-02, -4.95644845e-02, -2.89209001e-03,\n",
              "         1.44724837e-02,  2.78205145e-03, -4.92708497e-02,  7.63412192e-02,\n",
              "         7.50960875e-03,  1.01782113e-01, -7.77720511e-02,  1.05578043e-01,\n",
              "         2.95774862e-02,  2.56214682e-02, -1.69605985e-02, -1.23103661e-02,\n",
              "         1.32877184e-02, -7.12810010e-02, -5.29186567e-03,  1.01253510e-01,\n",
              "        -1.93345128e-03, -2.24841386e-02,  4.75296052e-03, -9.03277192e-03,\n",
              "         9.62685049e-02,  9.77217499e-03,  2.67203525e-03,  4.56169397e-02,\n",
              "         2.84885019e-02,  4.64772247e-02,  5.31795807e-02, -6.27199039e-02,\n",
              "        -7.63154775e-02, -5.88205792e-02,  6.60432596e-03, -6.97609223e-03,\n",
              "        -1.88348647e-02, -5.68267331e-02,  6.60022050e-02, -7.62496293e-02,\n",
              "        -7.97167793e-03,  4.08818163e-02,  5.14876731e-02,  1.34469531e-02,\n",
              "         1.51669672e-02,  1.20437043e-02, -1.01106651e-01,  7.91983679e-03,\n",
              "        -7.41565274e-03,  2.52420604e-02, -1.15711382e-02,  9.10023004e-02,\n",
              "        -4.89759818e-03, -3.03117912e-02,  9.31739062e-02, -5.07656150e-02,\n",
              "         3.90488133e-02,  4.96973991e-02,  2.98614390e-02,  3.61287743e-02,\n",
              "        -4.03025597e-02,  5.47437966e-02, -1.44371865e-02, -7.44232386e-02],\n",
              "       dtype=float32),\n",
              " 'He devoured a large quantity of pizza pie.': array([ 9.26586911e-02,  1.03879042e-01,  2.52973419e-02,  7.27764890e-02,\n",
              "        -9.09327790e-02, -2.72836331e-02,  9.71444100e-02,  6.31548539e-02,\n",
              "        -6.98689744e-03, -8.39226618e-02,  1.63507313e-02, -8.45772922e-02,\n",
              "        -1.99651755e-02,  2.80485470e-02,  2.64629275e-02, -1.16824582e-01,\n",
              "         1.11758441e-01, -1.96262561e-02,  4.99542709e-03, -3.96505594e-02,\n",
              "         5.88245317e-02,  3.11691631e-02,  2.69650184e-02, -5.09426445e-02,\n",
              "         1.68340262e-02,  1.30321607e-02,  1.51775125e-02, -9.19876248e-02,\n",
              "        -7.17586931e-03, -3.62625793e-02,  4.89717396e-03,  4.66717370e-02,\n",
              "         5.36134802e-02, -4.76557612e-02,  4.34957892e-02,  2.74556642e-03,\n",
              "         2.97938138e-02, -4.36551496e-02,  1.06163807e-01,  1.17183309e-02,\n",
              "         5.96725494e-02,  5.52862603e-03,  8.56723730e-03,  2.07107002e-03,\n",
              "        -2.13831142e-02, -1.33324265e-02, -7.86467344e-02, -2.22162344e-02,\n",
              "         5.05014956e-02,  6.51291683e-02, -6.66031539e-02, -1.32713923e-02,\n",
              "         1.89886689e-02, -6.03921562e-02,  3.04021016e-02, -6.71461150e-02,\n",
              "         8.08790699e-02,  3.06076668e-02,  5.72373532e-03, -1.72604322e-02,\n",
              "        -1.24687865e-01, -2.35749930e-02,  2.06168387e-02,  1.27432207e-02,\n",
              "         3.67180631e-02, -1.04314625e-01, -6.43979572e-03, -7.77296498e-02,\n",
              "        -3.19539197e-02,  1.01036385e-01,  4.01756056e-02,  7.24654794e-02,\n",
              "         2.47611571e-02, -5.41984402e-02, -4.52102674e-03, -3.86611670e-02,\n",
              "         9.58043244e-03, -6.23329580e-02, -3.66962217e-02, -3.80373187e-02,\n",
              "         2.27140710e-02,  5.61728887e-02, -7.59787634e-02,  1.45646194e-02,\n",
              "        -3.85403633e-02,  3.90401483e-02, -1.01489536e-02, -6.21294777e-04,\n",
              "        -4.76257242e-02,  3.53698730e-02, -9.64777370e-04, -4.93094511e-02,\n",
              "        -6.87496811e-02,  2.67795436e-02, -5.48597127e-02, -1.72837321e-02,\n",
              "        -6.14329912e-02, -8.54458809e-02, -6.18173648e-03,  3.19346152e-02,\n",
              "         1.79226790e-02,  5.42359389e-02,  4.38107364e-02, -6.14325441e-02,\n",
              "         1.85904559e-02,  8.96430109e-03, -4.85446043e-02,  7.93997422e-02,\n",
              "         4.87094261e-02,  5.02388291e-02, -1.50919147e-02, -2.79688295e-02,\n",
              "        -1.53112449e-02, -2.44073197e-02,  1.53386481e-02,  1.29200546e-02,\n",
              "         3.40420790e-02, -4.37223166e-02, -8.84058774e-02,  3.34738940e-02,\n",
              "         4.06758823e-02,  4.06616693e-03, -3.97591107e-02,  8.26587379e-02,\n",
              "        -6.77212775e-02, -2.50223838e-02, -9.10377316e-03, -4.37171051e-33,\n",
              "         1.14387022e-02, -1.16551621e-02,  3.37441452e-02,  3.82436775e-02,\n",
              "         3.54883932e-02,  8.45947117e-02, -7.34267756e-03,  3.70556936e-02,\n",
              "        -9.26301721e-03, -4.62407358e-02,  1.76063634e-03, -2.79063396e-02,\n",
              "        -6.50270283e-02,  1.02642983e-01, -5.05771372e-04, -3.14896703e-02,\n",
              "         2.33523212e-02,  4.61929366e-02,  2.96222381e-02, -8.25962275e-02,\n",
              "        -1.03257522e-02, -6.71281889e-02,  5.04696229e-03, -1.26437182e-02,\n",
              "        -1.61499400e-02,  3.81573476e-02, -3.84982079e-02,  2.51688273e-03,\n",
              "        -3.04327570e-02, -3.83657403e-04,  3.60775851e-02,  4.00795192e-02,\n",
              "         4.22684923e-02,  3.13124806e-02,  1.18211910e-01, -1.61979720e-02,\n",
              "        -3.40253189e-02,  4.15354930e-02, -1.02417007e-01,  3.83476401e-03,\n",
              "        -1.64249893e-02,  2.69255694e-02,  3.15838940e-02,  4.32537543e-03,\n",
              "        -1.47809818e-01, -1.34320371e-03, -4.86062206e-02,  3.37007605e-02,\n",
              "         3.00361328e-02, -3.73297706e-02,  8.40776190e-02,  2.05459539e-02,\n",
              "         6.50587678e-02, -2.88388021e-02, -1.30372010e-02, -3.18085253e-02,\n",
              "         4.33760397e-02, -4.77435179e-02, -1.81195850e-03,  4.86688362e-03,\n",
              "         7.72783980e-02,  6.88843429e-02,  3.23205674e-03,  5.45225479e-02,\n",
              "        -1.00346804e-01, -8.38381145e-03, -2.44070701e-02,  1.96523145e-02,\n",
              "        -5.68317249e-02,  6.45358711e-02, -3.39961126e-02, -2.58985460e-02,\n",
              "         7.46819228e-02, -5.20028360e-02, -1.12593375e-01, -3.28743607e-02,\n",
              "        -4.32839692e-02,  1.54183237e-02, -1.76077075e-02,  3.61032709e-02,\n",
              "         4.27870639e-02, -3.61662842e-02,  7.33690858e-02, -4.71524857e-02,\n",
              "        -6.57481328e-02,  5.06875962e-02,  2.35686321e-02, -5.82318418e-02,\n",
              "         6.13828748e-02,  4.27952260e-02, -4.66163307e-02, -5.02617508e-02,\n",
              "         2.93626133e-02, -6.18205629e-02, -1.19411118e-01,  1.41557805e-33,\n",
              "        -9.10661072e-02,  8.20004344e-02, -1.21993311e-02,  1.69701651e-02,\n",
              "        -6.17359951e-03, -3.46245058e-02, -6.93323687e-02,  1.45188468e-02,\n",
              "        -1.62750538e-02, -9.35960785e-02, -2.25124825e-02,  1.13733802e-02,\n",
              "         1.23515539e-01, -4.10958678e-02, -4.21514688e-03,  1.17989950e-01,\n",
              "         3.77647094e-02,  6.12112805e-02, -8.86051077e-03,  1.70185678e-02,\n",
              "        -6.93621933e-02, -4.81454208e-02,  2.79897545e-02,  5.35243303e-02,\n",
              "        -2.99999844e-02,  6.28639311e-02,  2.35966332e-02,  6.90329401e-03,\n",
              "        -5.02606742e-02, -2.28960346e-03, -4.23269086e-02, -5.77929765e-02,\n",
              "        -2.50180662e-02, -1.39177497e-02, -2.28893980e-02,  9.17828232e-02,\n",
              "        -1.00953300e-02,  3.42455991e-02,  3.62381563e-02, -3.96151766e-02,\n",
              "        -4.29133400e-02, -6.60993904e-02,  2.77058594e-02,  6.65988326e-02,\n",
              "         4.38113362e-02, -2.58989017e-02,  3.19363512e-02, -2.20845733e-02,\n",
              "         3.86395790e-02,  7.54740834e-02, -1.12171974e-02,  3.57404281e-03,\n",
              "        -1.06260786e-02,  2.14684438e-02,  1.52335232e-02,  6.68336302e-02,\n",
              "        -3.79821621e-02,  7.03508258e-02, -1.19104758e-02, -8.93973038e-02,\n",
              "        -8.40029195e-02, -2.80236080e-02,  2.07338221e-02,  5.71527705e-02,\n",
              "        -1.12747587e-02,  3.46782394e-02,  2.66403500e-02, -2.56141126e-02,\n",
              "        -1.31900553e-02,  3.35978754e-02, -1.85441840e-02,  6.21116497e-02,\n",
              "         5.55023663e-02,  1.74784157e-02, -4.12545651e-02, -2.91418266e-02,\n",
              "        -9.82550904e-02, -1.48220621e-02, -4.36417423e-02,  5.44898736e-04,\n",
              "        -2.67492365e-02, -7.76270032e-02, -2.08121259e-03,  2.44963262e-02,\n",
              "         3.29482406e-02, -8.18781182e-02,  1.46674551e-03, -1.09212488e-01,\n",
              "        -7.26526529e-02,  5.27112596e-02, -3.90685163e-02,  9.13414359e-03,\n",
              "         6.36806190e-02, -2.59409100e-02,  8.29569548e-02, -1.79818347e-08,\n",
              "         2.22046524e-02, -3.58418413e-02, -3.36648338e-02,  1.42214373e-02,\n",
              "         1.09678604e-01, -4.36775945e-02, -3.69147211e-02,  2.89636832e-02,\n",
              "        -3.73639092e-02,  7.08654746e-02, -1.44068837e-01,  7.27688745e-02,\n",
              "         7.01104477e-02,  7.35834194e-03,  4.61371383e-03, -4.38697226e-02,\n",
              "         2.90383101e-02, -3.81179862e-02, -3.82664874e-02,  3.15927751e-02,\n",
              "        -2.12663524e-02,  1.75734852e-02,  2.31769513e-02, -4.13993523e-02,\n",
              "         4.18753512e-02, -2.14871019e-03, -1.64323729e-02,  3.80957201e-02,\n",
              "        -2.84533948e-03,  2.20263377e-02,  5.10775670e-02, -2.62834765e-02,\n",
              "        -1.20297529e-01, -3.84298079e-02,  5.19731231e-02,  2.23668516e-02,\n",
              "        -5.46426885e-02, -3.89294438e-02,  5.96147776e-02, -1.80351064e-02,\n",
              "        -4.51953560e-02,  5.68292663e-02,  3.40281203e-02,  4.01809737e-02,\n",
              "         9.10746586e-03, -8.80422071e-03, -7.73267820e-02, -8.39864835e-03,\n",
              "         4.25916724e-03,  8.52048770e-02,  2.63677631e-03,  9.57284719e-02,\n",
              "         9.62887239e-03, -2.09400970e-02,  1.38908044e-01, -7.22922087e-02,\n",
              "         6.46172985e-02,  3.89985740e-02,  1.61315780e-02,  8.52322578e-02,\n",
              "        -6.59386534e-03,  6.99232295e-02,  6.42755851e-02, -1.16946414e-01],\n",
              "       dtype=float32)}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "text_embeddings_dict = dict(zip(texts, list(text_embeddings)))\n",
        "text_embeddings_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4524dda6b1528700",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-16T18:51:29.934975Z",
          "start_time": "2024-11-16T18:51:29.930973Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4524dda6b1528700",
        "outputId": "d23e79e6-c998-4853-e3ca-712a0491e4e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.77686167"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "dog_text_1 = \"The canine barked loudly.\"\n",
        "dog_text_2 = \"The dog made a noisy bark.\"\n",
        "compute_cosine_similarity(text_embeddings_dict[dog_text_1],\n",
        "                          text_embeddings_dict[dog_text_2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41a54b738df81e3d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-16T18:51:32.832398Z",
          "start_time": "2024-11-16T18:51:32.828648Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41a54b738df81e3d",
        "outputId": "3f63bb38-7802-464f-99ed-38691ea3e0c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.78713405"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "pizza_text_1 = \"He ate a lot of pizza.\"\n",
        "pizza_test_2 = \"He devoured a large quantity of pizza pie.\"\n",
        "compute_cosine_similarity(text_embeddings_dict[pizza_text_1],\n",
        "                          text_embeddings_dict[pizza_test_2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7528dbc0c2c0f58",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-16T18:52:47.408812Z",
          "start_time": "2024-11-16T18:52:47.404912Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7528dbc0c2c0f58",
        "outputId": "41b69c86-b1f3-4a7c-d5e4-b0349f5331cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09128271"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "compute_cosine_similarity(text_embeddings_dict[dog_text_1],\n",
        "                          text_embeddings_dict[pizza_text_1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d64e54efe84fda9",
      "metadata": {
        "id": "9d64e54efe84fda9"
      },
      "source": [
        "In the above code, you use `dict()` and `zip()` together to create a dictionary where the keys are the four sentences and the values are their embeddings. This allows you to directly look up the embeddings for each text. You then compute the cosine similarity between a few pairs of texts. Here are some important conclusions:\n",
        "\n",
        "* The cosine similarity between `\"The canine barked loudly\"` and `\"The dog made a noisy bark\"` is relatively high even though the two sentences use different words. The same is true for the similarity between `\"`He ate a lot of pizza\"` and `\"He devoured a large quantity of pizza pie\"`. Because the text embeddings encode semantic meaning, any pair of related texts should have a high cosine similarity.\n",
        "\n",
        "* As you might expect, the cosine similarity between `\"The canine barked loudly\"` and `\"He ate a lot of pizza\"` is low because the sentences are unrelated to each other.\n",
        "\n",
        "This example, while straightforward, illustrates a powerful idea that underpins vector databases. That is, you can take a collection of unstructured objects, compute and store their embeddings, and then compare these embeddings to one another or to new embeddings. In this case, the unstructured objects are text, but keep in mind that the same idea can work for other data like images and audio.\n",
        "\n",
        "Now that you’re up to speed on vectors and embeddings, you’re ready to get started with ChromaDB! In the next section, you’ll learn about vector databases and get a hands-on overview of ChromaDB."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6af8c879d33adc3",
      "metadata": {
        "id": "e6af8c879d33adc3"
      },
      "source": [
        "## Get Started With ChromaDB, an Open-Source Vector Database\n",
        "\n",
        "Now that you understand the mechanisms behind ChromaDB, you’re ready to tackle a real-world scenario. Say you have a library of thousands of documents, and you need a way to search through them.\n",
        "\n",
        "In particular, you want to be able to make queries that point you to relevant documents. For example, if your query is `find me documents containing financial information`, then you want whatever system you use to point you to a financial document in your library.\n",
        "\n",
        "How would you design this system? With your knowledge of vectors and embeddings, your first inclination might be to run all of the documents through an embedding algorithm and store the documents and embeddings together. You’d then convert a new query to an embedding and use cosine similarity to find the documents that are most relevant to the query.\n",
        "\n",
        "While you’re perfectly capable of writing the code for this, you’re sure there has to be something out there to do this for you. Enter vector databases!\n",
        "\n",
        "### What is a Vector Database?\n",
        "\n",
        "A vector database is a database that allows you to efficiently store and query embedding data. Vector databases extend the capabilities of traditional relational databases to embeddings. However, the key distinguishing feature of a vector database is that query results aren’t an exact match to the query. Instead, using a specified similarity metric, the vector database returns embeddings that are similar to a query.\n",
        "\n",
        "As an example use case, suppose you’ve stored company documents in a vector database. This means each document has been embedded and can be compared to other embeddings through a similarity metric like cosine similarity.\n",
        "\n",
        "The vector database will accept a query like \"how much revenue did the company make in Q2 2023\" and embed the query. It’ll then compare the embedded query to other embeddings in the vector database and return the documents that have embeddings that are most similar to the query embedding.\n",
        "\n",
        "In this example, perhaps the most similar document says something like \"Company XYZ reported $15 million in revenue for Q2 2023\". The vector database identified the document that had an embedding most similar to how much revenue did the company make in Q2 2023, which likely had a high similarity score based on the document’s semantics.\n",
        "\n",
        "To make this possible, vector databases are equipped with features that balance the speed and accuracy of query results. Here are the core components of a vector database that you should know about:\n",
        "\n",
        "* **Embedding function**: When using a vector database, oftentimes you’ll store and query data in its raw form, rather than uploading embeddings themselves. Internally, the vector database needs to know how to convert your data to embeddings, and you have to specify an embedding function for this. For text, you can use the embedding functions available in the `SentenceTransformers` library or any other function that maps raw text to vectors.\n",
        "\n",
        "* **Similarity metric**: To assess embedding similarity, you need a similarity metric like *cosine similarity*, *the dot product*, or *Euclidean distance*. As you learned previously, cosine similarity is a popular choice, but choosing the right similarity metric depends on your application.\n",
        "\n",
        "* **Indexing**: When you’re dealing with a large number of embeddings, comparing a query embedding to every embedding stored in the database is often too slow. To overcome this, vector databases employ indexing algorithms that group similar embeddings together.\n",
        "\n",
        "    At query time, the query embedding is compared to a smaller subset of embeddings based on the index. Because the embeddings recommended by the index aren’t guaranteed to have the highest similarity to the query, this is called approximate nearest neighbor search.\n",
        "\n",
        "* **Metadata**: You can store metadata with each embedding to help give context and make query results more precise. You can filter your embedding searches on metadata much like you would in a relational database. For example, you could store the year that a document was published as metadata and only look for similar documents that were published in a given year.\n",
        "\n",
        "* **Storage location**: With any kind of database, you need a place to store the data. Vector databases can store embeddings and metadata both in memory and on disk. Keeping data in memory allows for faster reads and writes, while writing to disk is important for persistent storage.\n",
        "\n",
        "* **CRUD operations**: Most vector databases support create, read, update, and delete (CRUD) operations. This means you can maintain and interact with data like you would in a relational database.\n",
        "\n",
        "There’s a whole lot more detail and complexity that you could explore with vector databases, but these core concepts should be enough to get you going. Next up, you’ll get your hands dirty with ChromaDB, one of the most popular and user-friendly vector databases around.\n",
        "\n",
        "### Meet ChromaDB for LLM Applications\n",
        "\n",
        "ChromaDB is an open-source vector database designed specifically for LLM applications. ChromaDB offers you both a user-friendly API and impressive performance, making it a great choice for many embedding applications.\n",
        "\n",
        "To get started, activate your virtual environment and run the following command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43b190d3ebc97b3b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-16T09:46:33.813307Z",
          "start_time": "2024-11-16T09:46:33.755853Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43b190d3ebc97b3b",
        "outputId": "e201a87d-b711-4889-c90c-9efa576c2731"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-0.5.20-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.9.2)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.26.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.7.2-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.28.2)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.28.2)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.20.3)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.6)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.68.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.13.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.11)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.27.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.1.0)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (4.25.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.15)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.28.2-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-instrumentation==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.49b2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b2)\n",
            "Collecting opentelemetry-util-http==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.49b2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.23.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.26.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-0.5.20-py3-none-any.whl (617 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m617.9/617.9 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.28.2-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.49b2-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_util_http-0.49b2-py3-none-any.whl (6.9 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.7.2-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (425 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.2/168.2 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=43db3ac263bc0179a4fc662b053b7cd78978f4456dbb3b81161fed389df1c6c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, durationpy, websockets, uvloop, uvicorn, python-dotenv, pyproject_hooks, protobuf, overrides, opentelemetry-util-http, mmh3, humanfriendly, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-proto, coloredlogs, build, opentelemetry-exporter-otlp-proto-common, onnxruntime, kubernetes, fastapi, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.5.20 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.5 httptools-0.6.4 humanfriendly-10.0 kubernetes-31.0.0 mmh3-5.0.1 monotonic-1.6 onnxruntime-1.20.1 opentelemetry-exporter-otlp-proto-common-1.28.2 opentelemetry-exporter-otlp-proto-grpc-1.28.2 opentelemetry-instrumentation-0.49b2 opentelemetry-instrumentation-asgi-0.49b2 opentelemetry-instrumentation-fastapi-0.49b2 opentelemetry-proto-1.28.2 opentelemetry-util-http-0.49b2 overrides-7.7.0 posthog-3.7.2 protobuf-5.28.3 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.0.1 starlette-0.41.3 uvicorn-0.32.1 uvloop-0.21.0 watchfiles-0.24.0 websockets-14.1\n"
          ]
        }
      ],
      "source": [
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f410581ab7b4756",
      "metadata": {
        "id": "7f410581ab7b4756"
      },
      "source": [
        "Because you have a grasp on vectors and embeddings, and you understand the motivation behind vector databases, the best way to get started is with an example. For this example, you’ll store ten documents to search over. To illustrate the power of embeddings and semantic search, each document covers a different topic, and you’ll see how well ChromaDB associates your queries with similar documents.\n",
        "\n",
        "You’ll start by importing dependencies, defining configuration variables, and creating a ChromaDB client:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "368be0b36a5a9a12",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-17T03:06:21.072240Z",
          "start_time": "2024-11-17T03:06:21.065436Z"
        },
        "id": "368be0b36a5a9a12"
      },
      "outputs": [],
      "source": [
        "import chromadb\n",
        "\n",
        "CHROMA_DATA_PATH = \"chroma_data/\"\n",
        "EMBED_MODEL = \"all-MiniLM-L6-v2\"\n",
        "COLLECTION_NAME = \"demo_docs\"\n",
        "\n",
        "client = chromadb.PersistentClient(path=CHROMA_DATA_PATH)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99006d2442d8b0ca",
      "metadata": {
        "id": "99006d2442d8b0ca"
      },
      "source": [
        "You first import `chromadb` and then import the `embedding_functions` module, which you’ll use to specify the embedding function. Next, you specify the location where ChromaDB will store the embeddings on your machine in `CHROMA_DATA_PATH`, the name of the embedding model that you’ll use in `EMBED_MODEL`, and the name of your first collection in `COLLECTION_NAME`.\n",
        "\n",
        "You then instantiate a `PersistentClient` object that writes your embedding data to `CHROMA_DB_PATH.` By doing this, you ensure that data will be stored at `CHROMA_DB_PATH` and persist to new clients. Alternatively, you can use `chromadb.Client()` to instantiate a ChromaDB instance that only writes to memory and doesn’t persist on disk.\n",
        "\n",
        "Next, you instantiate your embedding function and the ChromaDB collection to store your documents in:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4936a8bdfd33b9b7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-17T03:04:18.884108Z",
          "start_time": "2024-11-17T03:04:05.853773Z"
        },
        "id": "4936a8bdfd33b9b7"
      },
      "outputs": [],
      "source": [
        "from chromadb.utils import embedding_functions\n",
        "\n",
        "embedding_func = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=EMBED_MODEL)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8ec3974d3aadba5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-17T03:06:32.778982Z",
          "start_time": "2024-11-17T03:06:32.669368Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "d8ec3974d3aadba5",
        "outputId": "e39a85c3-fab1-44a6-df7f-3103980717c5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "UniqueConstraintError",
          "evalue": "Collection demo_docs already exists",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUniqueConstraintError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-1ea7193959a4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m collection = client.create_collection(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCOLLECTION_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0membedding_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"hnsw:space\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"cosine\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/chromadb/api/client.py\u001b[0m in \u001b[0;36mcreate_collection\u001b[0;34m(self, name, configuration, metadata, embedding_function, data_loader, get_or_create)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mget_or_create\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     ) -> Collection:\n\u001b[0;32m--> 147\u001b[0;31m         model = self._server.create_collection(\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/chromadb/telemetry/opentelemetry/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0;32mglobal\u001b[0m \u001b[0mtracer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgranularity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtrace_granularity\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mgranularity\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtracer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/chromadb/api/segment.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rate_limit_enforcer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrate_limit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/chromadb/rate_limit/simple_rate_limit/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/chromadb/api/segment.py\u001b[0m in \u001b[0;36mcreate_collection\u001b[0;34m(self, name, configuration, metadata, get_or_create, tenant, database)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# TODO: Let sysdb create the collection directly from the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         coll, created = self._sysdb.create_collection(\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/chromadb/telemetry/opentelemetry/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0;32mglobal\u001b[0m \u001b[0mtracer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgranularity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtrace_granularity\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mgranularity\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtracer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/chromadb/db/mixins/sysdb.py\u001b[0m in \u001b[0;36mcreate_collection\u001b[0;34m(self, id, name, configuration, segments, metadata, dimension, get_or_create, tenant, database)\u001b[0m\n\u001b[1;32m    239\u001b[0m                 )\n\u001b[1;32m    240\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mUniqueConstraintError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Collection {name} already exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         collection = Collection(\n",
            "\u001b[0;31mUniqueConstraintError\u001b[0m: Collection demo_docs already exists"
          ]
        }
      ],
      "source": [
        "collection = client.create_collection(\n",
        "    name=COLLECTION_NAME,\n",
        "    embedding_function=embedding_func,\n",
        "    metadata={\"hnsw:space\": \"cosine\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb305022ec581b00",
      "metadata": {
        "id": "bb305022ec581b00"
      },
      "source": [
        "You specify an embedding function from the SentenceTransformers library. ChromaDB will use this to embed all your documents and queries. In this example, you’ll continue using the `\"all-MiniLM-L6-v2\"` model. You then create your first collection.\n",
        "\n",
        "A collection is the object that stores your embedded documents along with any associated metadata. If you’re familiar with relational databases, then you can think of a collection as a table. In this example, your collection is named `demo_docs`, it uses the `\"all-MiniLM-L6-v2\"` embedding function that you instantiated, and it uses the cosine similarity distance function as specified by `metadata={\"hnsw:space\": \"cosine\"}`.\n",
        "\n",
        "`metadata={\"hnsw:space\": 'cosine'}`  configures ChromaDB to use the `HNSW` algorithm with cosine distance for efficient and relevant similarity search within your collection. HNSW stands for **Hierarchical Navigable Small World**. It's a powerful algorithm for approximate nearest neighbor search (ANN). Essentially, it creates an efficient structure to find vectors similar to your query vector without exhaustively comparing it to every vector in the collection. HNSW is a powerful **indexing** technique that makes searching for similar vectors in high-dimensional spaces much faster and more efficient. HNSW significantly speeds up similarity search, especially for large datasets. It's crucial for making ChromaDB performant.\n",
        "\n",
        "`hnsw:space:` is a specific metadata key within ChromaDB that tells the HNSW index which distance metric to use when comparing vectors.\n",
        "\n",
        "The last step in setting up your collection is to add documents and metadata:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59421abb293821ee",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-17T03:06:47.145563Z",
          "start_time": "2024-11-17T03:06:46.812084Z"
        },
        "id": "59421abb293821ee"
      },
      "outputs": [],
      "source": [
        "documents = [\n",
        "    \"The latest iPhone model comes with impressive features and a powerful camera.\",\n",
        "    \"Exploring the beautiful beaches and vibrant culture of Bali is a dream for many travelers.\",\n",
        "    \"Einstein's theory of relativity revolutionized our understanding of space and time.\",\n",
        "    \"Traditional Italian pizza is famous for its thin crust, fresh ingredients, and wood-fired ovens.\",\n",
        "    \"The American Revolution had a profound impact on the birth of the United States as a nation.\",\n",
        "    \"Regular exercise and a balanced diet are essential for maintaining good physical health.\",\n",
        "    \"Leonardo da Vinci's Mona Lisa is considered one of the most iconic paintings in art history.\",\n",
        "    \"Climate change poses a significant threat to the planet's ecosystems and biodiversity.\",\n",
        "    \"Startup companies often face challenges in securing funding and scaling their operations.\",\n",
        "    \"Beethoven's Symphony No. 9 is celebrated for its powerful choral finale, 'Ode to Joy.'\",\n",
        "]\n",
        "\n",
        "genres = [\n",
        "    \"technology\",\n",
        "    \"travel\",\n",
        "    \"science\",\n",
        "    \"food\",\n",
        "    \"history\",\n",
        "    \"fitness\",\n",
        "    \"art\",\n",
        "    \"climate change\",\n",
        "    \"business\",\n",
        "    \"music\",\n",
        "]\n",
        "\n",
        "collection.add(\n",
        "    documents = documents,\n",
        "    ids=[f\"id{i}\" for i in range(len(documents))],\n",
        "    metadatas=[{\"genre\": genre} for genre in genres],\n",
        "\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faf6b4f5847113a",
      "metadata": {
        "id": "faf6b4f5847113a"
      },
      "source": [
        "In this block, you define a list of ten documents in `documents` and specify the genre of each document in `genres`. You then add the documents and genres using `collection.add()`. Each document in the documents argument is embedded and stored in the collection. You also have to define the `ids` argument to uniquely identify each document and embedding in the collection. You accomplish this with a list comprehension that creates a list of ID strings.\n",
        "\n",
        "The `metadatas` argument is optional, but most of the time, it’s useful to store metadata with your embeddings. In this case, you define a single metadata field, *\"genre\"*, that records the genre of each document. When you query a document, metadata provides you with additional information that can be helpful to better understand the document’s contents. You can also filter on metadata fields, just like you would in a relational database query.\n",
        "\n",
        "With documents embedded and stored in a collection, you’re ready to run some semantic queries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbab1e724a3a6a5f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-17T03:06:49.590919Z",
          "start_time": "2024-11-17T03:06:49.567694Z"
        },
        "id": "dbab1e724a3a6a5f"
      },
      "outputs": [],
      "source": [
        "query_results = collection.query(\n",
        "    query_texts=[\"Find me some delicious food!\"],\n",
        "    n_results=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e617193978e5189",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-17T03:06:51.770104Z",
          "start_time": "2024-11-17T03:06:51.765223Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e617193978e5189",
        "outputId": "7a2e8805-7198-48a6-d772-cf2001f92ad6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['ids', 'embeddings', 'documents', 'uris', 'data', 'metadatas', 'distances', 'included'])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "query_results.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8657934916489a0c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-17T03:06:53.089397Z",
          "start_time": "2024-11-17T03:06:53.085564Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8657934916489a0c",
        "outputId": "cf88052e-4749-46da-f8df-91b077bfe7e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Traditional Italian pizza is famous for its thin crust, fresh ingredients, and wood-fired ovens.']]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "query_results[\"documents\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cf4079b5e04983",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-16T10:06:01.954358Z",
          "start_time": "2024-11-16T10:06:01.951316Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cf4079b5e04983",
        "outputId": "e7321b6a-ad18-4c23-a0d4-de4927e34c24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['id3']]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "query_results[\"ids\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adb764aa088d8951",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-16T10:06:06.804800Z",
          "start_time": "2024-11-16T10:06:06.801189Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adb764aa088d8951",
        "outputId": "c826d36b-c1e9-4b2f-9543-50379eab81ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.7638264485407227]]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "query_results[\"distances\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9f45c9af04bd20f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-16T10:06:18.454722Z",
          "start_time": "2024-11-16T10:06:18.451058Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9f45c9af04bd20f",
        "outputId": "ef3b2585-da1e-4311-96f3-62a0ca63437c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'genre': 'food'}]]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "query_results[\"metadatas\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c10096099df12172",
      "metadata": {
        "id": "c10096099df12172"
      },
      "source": [
        "In this example, you query the `demo_docs` collection for documents that are most similar to the sentence *Find me some delicious food!*. You accomplish this using `collection.query()`, where you pass your queries in `query_texts` and specify the number of similar documents to find with `n_results`. In this case, you only asked for the single document that’s most similar to your query.\n",
        "\n",
        "The results returned by `collection.query()` are stored in a dictionary with the keys *ids*, *distances*, *metadatas*, *embeddings*, and *documents*. This is the same information that you added to your collection at the beginning, but it’s filtered down to match your query. In other words, `collection.query()` returns all of the stored information about documents that are most similar to your query.\n",
        "\n",
        "As you can see, the embedding for *Traditional Italian pizza is famous for its thin crust, fresh ingredients, and wood-fired ovens* was most similar to the query *Find me some delicious food*. You probably agree that this document is the closest match. You can also see the ID, metadata, and distance associated with the matching document embedding. Here, you’re using cosine distance, which is one minus the cosine similarity between two embeddings.\n",
        "\n",
        "With `collection.query()`, you’re not limited to single queries or single results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35ef56db0c6aee9f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-17T03:06:55.401613Z",
          "start_time": "2024-11-17T03:06:55.379267Z"
        },
        "id": "35ef56db0c6aee9f"
      },
      "outputs": [],
      "source": [
        "query_results = collection.query(\n",
        "    query_texts=[\"Teach me about history\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3395780f6813195a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-17T02:50:05.350203Z",
          "start_time": "2024-11-17T02:50:05.346599Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3395780f6813195a",
        "outputId": "583f28e0-ea0e-4a4c-bf5b-9e49b28955c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Einstein's theory of relativity revolutionized our understanding of space and time.\",\n",
              " 'The American Revolution had a profound impact on the birth of the United States as a nation.',\n",
              " \"Leonardo da Vinci's Mona Lisa is considered one of the most iconic paintings in art history.\",\n",
              " 'Exploring the beautiful beaches and vibrant culture of Bali is a dream for many travelers.',\n",
              " \"Climate change poses a significant threat to the planet's ecosystems and biodiversity.\",\n",
              " 'The latest iPhone model comes with impressive features and a powerful camera.',\n",
              " \"Beethoven's Symphony No. 9 is celebrated for its powerful choral finale, 'Ode to Joy.'\",\n",
              " 'Regular exercise and a balanced diet are essential for maintaining good physical health.',\n",
              " 'Traditional Italian pizza is famous for its thin crust, fresh ingredients, and wood-fired ovens.',\n",
              " 'Startup companies often face challenges in securing funding and scaling their operations.']"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "query_results[\"documents\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36f0e8b7966bd343",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-17T02:50:10.387101Z",
          "start_time": "2024-11-17T02:50:10.383251Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36f0e8b7966bd343",
        "outputId": "d7cd5a37-9c1e-449d-8c7d-26aab4b60ebe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6265882786137,\n",
              " 0.6904192995177738,\n",
              " 0.8771599648570388,\n",
              " 0.9187455171695804,\n",
              " 0.9201708074723751,\n",
              " 0.9903300023447454,\n",
              " 1.0029226760096814,\n",
              " 1.0276568123963041,\n",
              " 1.0680427566360333,\n",
              " 1.0846893520811818]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "query_results[\"distances\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c7144ed10cb8782",
      "metadata": {
        "id": "6c7144ed10cb8782"
      },
      "source": [
        " Here, you pass two queries into `collection.query()`, *Teach me about history* and *What’s going on in the world*. You also request the two most similar documents for each query by specifying n_results=2. Lastly, by passing `include=[\"documents\", \"distances\"]`, you ensure that the dictionary only contains the documents and their embedding distances.\n",
        "\n",
        "Calling `query_results[\"documents\"][0]` shows you the two most similar documents to the first query in query_texts, and `query_results[\"distances\"][0]` contains the corresponding embedding distances. As an example, the cosine distance between *Teach me about history* and *Einstein’s theory of relativity revolutionized our understanding of space and time* is about **0.627**.\n",
        "\n",
        "Similarly, `query_results[\"documents\"][1]` shows you the two most similar documents to the second query in `query_texts`, and `query_results[\"distances\"][1]` contains the corresponding embedding distances. For this query, the two most similar documents weren’t as strong of a match as in the first query. Recall that cosine distance is one minus cosine similarity, so a cosine distance of **0.80** corresponds to a cosine similarity of **0.20**.\n",
        "\n",
        "Cosine Similarity vs. Cosine Distance\n",
        "\n",
        "Cosine Similarity: Measures the similarity between two vectors. It ranges from -1 (completely opposite) to 1 (identical).\n",
        "Cosine Distance: Measures the distance or dissimilarity between two vectors. It's inversely related to cosine similarity.\n",
        "\n",
        "ChromaDB, by default, returns cosine distances.  Therefore:\n",
        "\n",
        "* Lower values mean higher similarity. A distance of 0 means the vectors are identical.\n",
        "* Higher values mean lower similarity. A distance of 1 means the vectors are orthogonal (no similarity).\n",
        "\n",
        "To get the cosine similarity, you would subtract these values from 1.\n",
        "\n",
        "\n",
        "> Note: Keep in mind that so-called similar documents returned from a semantic search over embeddings may not actually be relevant to the task that you’re trying to solve. The success of a semantic search is somewhat subjective, and you or your stakeholders might not agree on the quality of the results.\n",
        "> If there are no relevant documents in your collection for a given query, or your embedding algorithm wasn’t trained on the right or enough data, then your results might be poor. It’s up to you to understand your application, your stakeholders’ expectations, and the limitations of your embedding algorithm and document collection.\n",
        "\n",
        "Another awesome feature of ChromaDB is the ability to filter queries on metadata. To motivate this, suppose you want to find the single document that’s most related to music history. You might run this query:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fef881310fec8e5c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-17T03:06:58.907450Z",
          "start_time": "2024-11-17T03:06:58.888716Z"
        },
        "id": "fef881310fec8e5c"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4bc7456ac59f988",
      "metadata": {
        "id": "b4bc7456ac59f988"
      },
      "source": [
        "Your query is *Teach me about history*, and the most similar document is *Einstein's theory of relativity revolutionized our understanding of space and time.*. Since our interest is in music history, this isn’t quite the result that you’re looking for. Because you’re particularly interested in music history, you can filter on the `\"genre\"` metadata field to search over more relevant documents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cdbf781847316f0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-17T02:58:20.343237Z",
          "start_time": "2024-11-17T02:58:20.285602Z"
        },
        "id": "7cdbf781847316f0"
      },
      "outputs": [],
      "source": [
        "collection.query(\n",
        "    query_texts=[\"Teach me about history\"],\n",
        "    where={},\n",
        "    n_results=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87c2b176d731952c",
      "metadata": {
        "id": "87c2b176d731952c"
      },
      "source": [
        "In this query, you specify in the where argument that you’re only looking for documents with the \"music\" genre. To apply filters, ChromaDB expects a dictionary where the keys are metadata names and the values are dictionaries specifying how to filter. In plain English, you can interpret `{\"genre\": {\"$eq\": \"music\"}}` as *filter the collection where the \"genre\" metadata field equals \"music\"*.\n",
        "\n",
        "As you can see, the document about Beethoven’s Symphony No. 9 is the most similar document. Of course, for this example, there’s only one document with the music genre.\n",
        "\n",
        "To make it slightly more difficult, you could filter on both history and music:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61599084178ca336",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-17T02:59:09.933582Z",
          "start_time": "2024-11-17T02:59:09.896222Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61599084178ca336",
        "outputId": "74d9cfea-3b23-4c07-b119-4895aef151d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['The American Revolution had a profound impact on the birth of the United States as a nation.',\n",
              "  \"Beethoven's Symphony No. 9 is celebrated for its powerful choral finale, 'Ode to Joy.'\"]]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "query_results = collection.query(\n",
        "    query_texts=[\"Teach me about history\"],\n",
        "    where={\"genre\": {\"$in\": [\"music\", \"history\"]}},\n",
        "    n_results=2,\n",
        ")\n",
        "\n",
        "query_results[\"documents\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0f0e7e01ef5a0c1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-16T10:14:43.356937Z",
          "start_time": "2024-11-16T10:14:43.352616Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0f0e7e01ef5a0c1",
        "outputId": "4a8d384c-ad2d-48d8-e2d7-54c98a2150b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.6904192995177738, 1.0029226760096814]]"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "query_results[\"distances\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6da3f03ff46d290a",
      "metadata": {
        "id": "6da3f03ff46d290a"
      },
      "source": [
        "This query filters the collection of documents that have either a music or history genre, as specified by `where={\"genre\": {\"$in\": [\"music\", \"history\"]}}`. As you can see, the Beethoven document is still the most similar, while the American Revolution document is a close second. These were straightforward filtering examples on a single metadata field, but ChromaDB also supports other filtering operations that you might need.\n",
        "\n",
        "If you want to update existing documents, embeddings, or metadata, then you can use collection`.update()`. This requires you to know the IDs of the data that you want to update. In this example, you’ll update both the documents and metadata for \"id1\" and \"id2\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "434f4b7a43af8d4a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-17T03:07:03.205970Z",
          "start_time": "2024-11-17T03:07:03.128423Z"
        },
        "id": "434f4b7a43af8d4a"
      },
      "outputs": [],
      "source": [
        "collection.update(\n",
        "    ids=[\"id1\", \"id2\"],\n",
        "    documents=[\n",
        "        \"The latest iPhone model comes with impressive features and a powerful camera.\",\n",
        "        \"Bali has beautiful beaches.\"\n",
        "    ],\n",
        "    metadatas=[{\"genre\": \"tech\"}, {\"genre\": \"beaches\"}]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f013bd1ce49619b9",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-17T03:07:05.593020Z",
          "start_time": "2024-11-17T03:07:05.588164Z"
        },
        "id": "f013bd1ce49619b9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "32e65ab6adb3d92b",
      "metadata": {
        "id": "32e65ab6adb3d92b"
      },
      "source": [
        "Here, you rename the documents for \"id1\" and \"id2\", and you also modify their metadata. To confirm that your update worked, you call `collection.get(ids=[\"id1\", \"id2\"])` and can see that you’ve successfully updated both documents and their metadata.\n",
        "\n",
        "If you’re not sure whether a document exists for an ID, you can use `collection.upsert()`. This works the same way as `collection.update()`, except it’ll insert new documents for IDs that don’t exist.\n",
        "\n",
        "Lastly, if you want to delete any items in the collection, then you can use `collection.delete()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c3449433e20a037",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-17T03:07:07.300858Z",
          "start_time": "2024-11-17T03:07:07.244778Z"
        },
        "id": "2c3449433e20a037"
      },
      "outputs": [],
      "source": [
        "collection.delete(ids=[\"id1\", \"id2\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "616a1b53f9467019",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-17T03:07:09.714371Z",
          "start_time": "2024-11-17T03:07:09.707158Z"
        },
        "id": "616a1b53f9467019"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}